{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character level language model - Dinosaurus land\n",
    "### Keras Implementation of the Deep-Learning Specializiation project\n",
    "\n",
    "\n",
    "Naming new dinos using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerardoduran/anaconda/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, SimpleRNN, Activation, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ix(encoding):\n",
    "    \"\"\"\n",
    "    Decode an encoded dinosaur sequence presented as an\n",
    "    (n,1) numpy array\n",
    "    \"\"\"\n",
    "    string = \"\".join(ix_to_char[ix] for ix in encoding.ravel())\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"dinos.txt\", \"r\") as f:\n",
    "    dinos = f.read().lower()\n",
    "characters = sorted(list(set(dinos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at a small sample of the names in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['opisthocoelicaudia', 'skeleton', 'marshosaurus', 'tototlmimus',\n",
       "       'ozraptor', 'hylosaurus', 'elvisaurus'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(1643)\n",
    "np.random.choice(dinos.split(), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from all characters in the training dataset to a uniquex index\n",
    "char_to_ix = {ix:char for char, ix in enumerate(characters)}\n",
    "# Reverse map of char_to_ix to retrieve the index given the character\n",
    "ix_to_char = {char:ix for char, ix in enumerate(characters,)}\n",
    "\n",
    "nchars = len(characters)\n",
    "nvocab = len(dinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 19,903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((19903, 10, 1), (19903, 27))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the sequence to pass as training example\n",
    "seqlen = 10\n",
    "xtrain, ytrain = [], []\n",
    "for i in range(0, nvocab - seqlen):\n",
    "    xt = dinos[i: i + seqlen]\n",
    "    yt = dinos[i + seqlen]\n",
    "    xtrain.append([char_to_ix[char] for char in xt])\n",
    "    ytrain.append([char_to_ix[char] for char in yt])\n",
    "    \n",
    "# training dataset is now\n",
    "# of shape (xtrain X seqlen)\n",
    "print(f\"Number of training instances: {len(xtrain):,}\")\n",
    "\n",
    "# Reshaping into the form:\n",
    "# nfeatures X timesteps X features\n",
    "xtrain = np.reshape(xtrain, (-1, seqlen, 1))\n",
    "# Normalizing values\n",
    "#xtrain = xtrain / nvocab\n",
    "# Transorming output values to be\n",
    "# One-hot encoded\n",
    "ytrain = to_categorical(ytrain)\n",
    "xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First five instances in the training dataset: A `seqlen` number characters followed by the next character of the dinosaur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  3  8  5 14 15 19  1 21]\n",
      "'aachenosau'\n",
      "'r'\n",
      "\n",
      "[ 1  3  8  5 14 15 19  1 21 18]\n",
      "'achenosaur'\n",
      "'u'\n",
      "\n",
      "[ 3  8  5 14 15 19  1 21 18 21]\n",
      "'chenosauru'\n",
      "'s'\n",
      "\n",
      "[ 8  5 14 15 19  1 21 18 21 19]\n",
      "'henosaurus'\n",
      "'\\n'\n",
      "\n",
      "[ 5 14 15 19  1 21 18 21 19  0]\n",
      "'enosaurus\\n'\n",
      "'a'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(xtrain[i].ravel())\n",
    "    print(repr(decode_ix(xtrain[i])))\n",
    "    print(repr(ix_to_char[np.where(ytrain[i] == 1)[0][0]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19903/19903 [==============================] - 3s 175us/step - loss: 2.4776\n",
      "Epoch 2/50\n",
      "19903/19903 [==============================] - 3s 165us/step - loss: 2.3139\n",
      "Epoch 3/50\n",
      "19903/19903 [==============================] - 3s 167us/step - loss: 2.2342\n",
      "Epoch 4/50\n",
      "19903/19903 [==============================] - 3s 166us/step - loss: 2.1627\n",
      "Epoch 5/50\n",
      "19903/19903 [==============================] - 3s 169us/step - loss: 2.1125\n",
      "Epoch 6/50\n",
      "19903/19903 [==============================] - 3s 165us/step - loss: 2.0584\n",
      "Epoch 7/50\n",
      "19903/19903 [==============================] - 3s 167us/step - loss: 2.0195\n",
      "Epoch 8/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.9769\n",
      "Epoch 9/50\n",
      "19903/19903 [==============================] - 3s 175us/step - loss: 1.9482\n",
      "Epoch 10/50\n",
      "19903/19903 [==============================] - 3s 162us/step - loss: 1.9201\n",
      "Epoch 11/50\n",
      "19903/19903 [==============================] - 3s 175us/step - loss: 1.8869\n",
      "Epoch 12/50\n",
      "19903/19903 [==============================] - 3s 155us/step - loss: 1.8581\n",
      "Epoch 13/50\n",
      "19903/19903 [==============================] - 4s 204us/step - loss: 1.8267\n",
      "Epoch 14/50\n",
      "19903/19903 [==============================] - 4s 182us/step - loss: 1.8056\n",
      "Epoch 15/50\n",
      "19903/19903 [==============================] - 3s 158us/step - loss: 1.7825\n",
      "Epoch 16/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.7517\n",
      "Epoch 17/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.7318\n",
      "Epoch 18/50\n",
      "19903/19903 [==============================] - 3s 154us/step - loss: 1.7040\n",
      "Epoch 19/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.6851\n",
      "Epoch 20/50\n",
      "19903/19903 [==============================] - 3s 153us/step - loss: 1.6629\n",
      "Epoch 21/50\n",
      "19903/19903 [==============================] - 3s 157us/step - loss: 1.6411\n",
      "Epoch 22/50\n",
      "19903/19903 [==============================] - 3s 162us/step - loss: 1.6238\n",
      "Epoch 23/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.6007\n",
      "Epoch 24/50\n",
      "19903/19903 [==============================] - 3s 160us/step - loss: 1.5800\n",
      "Epoch 25/50\n",
      "19903/19903 [==============================] - 3s 158us/step - loss: 1.5601\n",
      "Epoch 26/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.5423\n",
      "Epoch 27/50\n",
      "19903/19903 [==============================] - 3s 153us/step - loss: 1.5197\n",
      "Epoch 28/50\n",
      "19903/19903 [==============================] - 3s 153us/step - loss: 1.5087\n",
      "Epoch 29/50\n",
      "19903/19903 [==============================] - 3s 152us/step - loss: 1.4908\n",
      "Epoch 30/50\n",
      "19903/19903 [==============================] - 3s 152us/step - loss: 1.4683\n",
      "Epoch 31/50\n",
      "19903/19903 [==============================] - 3s 150us/step - loss: 1.4504\n",
      "Epoch 32/50\n",
      "19903/19903 [==============================] - 3s 152us/step - loss: 1.4360\n",
      "Epoch 33/50\n",
      "19903/19903 [==============================] - 3s 152us/step - loss: 1.4179\n",
      "Epoch 34/50\n",
      "19903/19903 [==============================] - 3s 152us/step - loss: 1.4068\n",
      "Epoch 35/50\n",
      "19903/19903 [==============================] - 3s 155us/step - loss: 1.3949\n",
      "Epoch 36/50\n",
      "19903/19903 [==============================] - 3s 154us/step - loss: 1.3755\n",
      "Epoch 37/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.3656\n",
      "Epoch 38/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.3456\n",
      "Epoch 39/50\n",
      "19903/19903 [==============================] - 3s 165us/step - loss: 1.3316\n",
      "Epoch 40/50\n",
      "19903/19903 [==============================] - 3s 169us/step - loss: 1.3192\n",
      "Epoch 41/50\n",
      "19903/19903 [==============================] - 3s 170us/step - loss: 1.3054\n",
      "Epoch 42/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.2926\n",
      "Epoch 43/50\n",
      "19903/19903 [==============================] - 3s 169us/step - loss: 1.2780\n",
      "Epoch 44/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.2720\n",
      "Epoch 45/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.2585\n",
      "Epoch 46/50\n",
      "19903/19903 [==============================] - 4s 182us/step - loss: 1.2438\n",
      "Epoch 47/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.2309\n",
      "Epoch 48/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.2205\n",
      "Epoch 49/50\n",
      "19903/19903 [==============================] - 3s 171us/step - loss: 1.2115\n",
      "Epoch 50/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.2045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1819ace6d8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "### Constructing an RNN model with keras ###\n",
    "# Input with shape of a single training instance, we\n",
    "# do not take into account the number of training examples\n",
    "xin = Input(shape=xtrain.shape[1:])\n",
    "# A recurrent neural network cell with tanh activation function\n",
    "# and 256 units\n",
    "x = SimpleRNN(256, activation=\"tanh\")(xin)\n",
    "# The output of each training example, after feeding\n",
    "# sqlen characters is a desne \"feedforward\" neural network\n",
    "# with softax activation function\n",
    "# The following code is equivalent to:\n",
    "# x = Dense(ytrain.shape[1], activation=\"softmax\")(x)\n",
    "x = Dense(ytrain.shape[1])(x)\n",
    "x = Activation(\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=xin, outputs=x)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(xtrain, ytrain, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:'r\\nsmilodon'\n",
      "\n",
      "ciangonnsaurus\n",
      "aracamatitan\n",
      "atchaeoraptor\n",
      "archaeornithosaurus\n",
      "aracamatitan\n",
      "atchaeoraptor\n",
      "archaeornithosaurus\n",
      "aracamatitan\n",
      "atchaeoraptor\n",
      "archaeornitho\n",
      "...Done...\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(xtrain)-1)\n",
    "pattern = xtrain[start].ravel()\n",
    "print(\"Seed:\", end=\"\")\n",
    "print(repr(''.join([ix_to_char[value] for value in pattern])))\n",
    "# generate characters\n",
    "for i in range(150):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = ix_to_char[index]\n",
    "    #seq_in = [ix_to_char[value] for value in pattern]\n",
    "    print(result, end=\"\")\n",
    "    pattern = np.append(pattern, index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\n...Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset: Outputs\n",
    "dinos_list = [[char_to_ix[c] for c in d + \"\\n\"] for d in dinos.split()]\n",
    "maxlen =  len(max(dinos_list, key=len))\n",
    "ndinos = len(dinos_list)\n",
    "nchars = len(characters)\n",
    "xtrain = np.zeros((ndinos, maxlen, nchars))\n",
    "ytrain = np.zeros((ndinos, maxlen, nchars))\n",
    "\n",
    "xtrain = np.zeros((ndinos, maxlen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xin = Input(shape=(maxlen,))\n",
    "x = SimpleRNN(10, activation=\"tanh\")(xin)\n",
    "x = Dense()\n",
    "x = Activation(\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=xin, outputs=x)\n",
    "model.compile(\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.zeros((1, maxlen, nchars)))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
