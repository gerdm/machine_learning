{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks With TensorFlow\n",
    "## Stable implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import variance_scaling_initializer # He-initializer\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyter_tf_graph import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28 * 28) / 255.0\n",
    "X_test = X_test.reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1643)\n",
    "img_ixs = np.random.randint(0, X_train.shape[0], 6)\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "fig.suptitle(\"Sample MNIST images\")\n",
    "for ix, img_ixs in enumerate(img_ixs):\n",
    "    ax = fig.add_subplot(3, 2, ix + 1)\n",
    "    ax.imshow(X_train[ix].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Fully Connected Deep Neural Network\n",
    "### FFNN V.01\n",
    "Feed forward neural network with sigmoid activation function and Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v01\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, activation=tf.nn.sigmoid, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.sigmoid, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.sigmoid, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.sigmoid, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.sigmoid, name=\"hidden5\")\n",
    "    outputs = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=outputs\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  40: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  80: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  120: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  160: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  200: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  240: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  280: Train Accuracy 011.24% | Test Accuracy 011.35%\n",
      "@Epoch  320: Train Accuracy 011.24% | Test Accuracy 011.35%\n",
      "@Epoch  360: Train Accuracy 011.24% | Test Accuracy 011.35%\n",
      "CPU times: user 24min 36s, sys: 4min 15s, total: 28min 51s%\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_test, y: y_test})\n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### FFNN V.02\n",
    "Feed forward neural network with elu activation function and Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v02\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, activation=tf.nn.elu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.elu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.elu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.elu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.elu, name=\"hidden5\")\n",
    "    outputs = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=outputs\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 006.13% | Test Accuracy 006.11%\n",
      "@Epoch  40: Train Accuracy 009.70% | Test Accuracy 009.56%\n",
      "@Epoch  80: Train Accuracy 014.78% | Test Accuracy 014.49%\n",
      "@Epoch  120: Train Accuracy 021.02% | Test Accuracy 021.13%\n",
      "@Epoch  160: Train Accuracy 027.68% | Test Accuracy 028.32%\n",
      "@Epoch  200: Train Accuracy 033.88% | Test Accuracy 034.71%\n",
      "@Epoch  240: Train Accuracy 039.29% | Test Accuracy 040.41%\n",
      "@Epoch  280: Train Accuracy 043.42% | Test Accuracy 044.78%\n",
      "@Epoch  320: Train Accuracy 047.05% | Test Accuracy 048.85%\n",
      "@Epoch  360: Train Accuracy 050.14% | Test Accuracy 051.77%\n",
      "CPU times: user 26min 10s, sys: 4min 11s, total: 30min 22s%\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_test, y: y_test})\n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### FFNN V.03\n",
    "Feed forward neural network with elu activation function and ADAM Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v03\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, activation=tf.nn.elu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.elu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.elu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.elu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.elu, name=\"hidden5\")\n",
    "    outputs = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=outputs\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 025.93% | Test Accuracy 026.65%\n",
      "@Epoch  40: Train Accuracy 091.63% | Test Accuracy 091.74%\n",
      "@Epoch  80: Train Accuracy 094.57% | Test Accuracy 094.37%\n",
      "@Epoch  120: Train Accuracy 096.32% | Test Accuracy 095.71%\n",
      "@Epoch  160: Train Accuracy 097.35% | Test Accuracy 096.45%\n",
      "@Epoch  200: Train Accuracy 098.10% | Test Accuracy 096.92%\n",
      "@Epoch  240: Train Accuracy 098.75% | Test Accuracy 097.19%\n",
      "@Epoch  280: Train Accuracy 098.96% | Test Accuracy 097.31%\n",
      "@Epoch  320: Train Accuracy 099.46% | Test Accuracy 097.39%\n",
      "@Epoch  360: Train Accuracy 099.69% | Test Accuracy 097.42%\n",
      "CPU times: user 26min 11s, sys: 4min 17s, total: 30min 28s%\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy],\n",
    "                               feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy],\n",
    "                                   feed_dict={X: X_test, y: y_test})\n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### FFNN V.04\n",
    "Feed forward neural network with elu activation function, ADAM Optimizer and Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v04/\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "eta = 0.9\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    z1 = tf.layers.dense(X, n_hidden, name=\"z1\")\n",
    "    z1_bn = tf.layers.batch_normalization(z1, training=training, momentum=eta)\n",
    "    a1 = tf.nn.elu(z1_bn)\n",
    "    \n",
    "    z2 = tf.layers.dense(a1, n_hidden, name=\"z2\")\n",
    "    z2_bn = tf.layers.batch_normalization(z2, training=training, momentum=eta)\n",
    "    a2 = tf.nn.elu(z2_bn)\n",
    "    \n",
    "    z3 = tf.layers.dense(a2, n_hidden, name=\"z3\")\n",
    "    z3_bn = tf.layers.batch_normalization(z3, training=training, momentum=eta)\n",
    "    a3 = tf.nn.elu(z3_bn)\n",
    "    \n",
    "    z4 = tf.layers.dense(a3, n_hidden, name=\"z4\")\n",
    "    z4_bn = tf.layers.batch_normalization(z4, training=training, momentum=eta)\n",
    "    a4 = tf.nn.elu(z4)\n",
    "    \n",
    "    z5 = tf.layers.dense(a4, n_hidden, name=\"z5\")\n",
    "    z5_bn = tf.layers.batch_normalization(z5, training=training, momentum=eta)\n",
    "    a5 = tf.nn.elu(z5_bn)\n",
    "    \n",
    "    output = tf.layers.dense(a5, n_hidden, name=\"output\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=output\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    \n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 005.91% | Test Accuracy 005.43%\n",
      "@Epoch  40: Train Accuracy 091.78% | Test Accuracy 092.06%\n",
      "@Epoch  80: Train Accuracy 095.16% | Test Accuracy 094.87%\n",
      "@Epoch  120: Train Accuracy 096.90% | Test Accuracy 096.05%\n",
      "@Epoch  160: Train Accuracy 097.95% | Test Accuracy 096.75%\n",
      "@Epoch  200: Train Accuracy 098.79% | Test Accuracy 097.07%\n",
      "@Epoch  240: Train Accuracy 099.32% | Test Accuracy 097.29%\n",
      "@Epoch  280: Train Accuracy 099.68% | Test Accuracy 097.37%\n",
      "@Epoch  320: Train Accuracy 099.87% | Test Accuracy 097.45%\n",
      "@Epoch  360: Train Accuracy 099.95% | Test Accuracy 097.43%\n",
      "CPU times: user 47min 35s, sys: 6min 25s, total: 54min7.43%\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Operations to compute the mean and standard deviation of the minibatch\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run([train_step, extra_update_ops], feed_dict={training: True, X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy],\n",
    "                               feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy],\n",
    "                                    feed_dict={X: X_test, y: y_test})\n",
    "        \n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch:03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network Version Comparison\n",
    "![FFNNs Comparisson](./images/ffnn_vs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "# Storing and Reusing TF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def a_plus_b(a, b): return a + b\n",
    "a_plus_3 = partial(a_plus_b, b=3)\n",
    "a_plus_3(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Building and Storing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v05/\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_output = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training_bool\")\n",
    "\n",
    "eta = 0.9\n",
    "batch_norm = partial(tf.layers.batch_normalization,\n",
    "                     momentum=eta, training=training)\n",
    "\n",
    "def hidden_layer(inputs, units, hi, activation=tf.nn.elu):\n",
    "    \"\"\"\n",
    "    Create the hidden layer of a feed forward neural\n",
    "    network with batch norm.\n",
    "    \"\"\"\n",
    "    zi = tf.layers.dense(inputs, units, name=f\"z{hi}\")\n",
    "    zi_bn = batch_norm(zi, name=f\"z_bn{hi}\")\n",
    "    ai = activation(zi_bn, name=f\"a{hi}\")\n",
    "    \n",
    "    return ai\n",
    "\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden = hidden_layer(X, n_hidden, 1)\n",
    "    # Creating 5 ELU layers\n",
    "    for h_ix in range(2, 6):\n",
    "        hidden = hidden_layer(hidden, n_hidden, h_ix)\n",
    "    output = tf.layers.dense(hidden, n_output, name=\"output\")\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=output\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    \n",
    "alpha = 0.005\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss, name=\"train_step\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_acc = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000: Train Accuracy 043.06% | Test Accuracy 043.12%\n",
      "@Epoch 040: Train Accuracy 096.41% | Test Accuracy 095.82%\n",
      "@Epoch 080: Train Accuracy 098.79% | Test Accuracy 097.35%\n",
      "@Epoch 120: Train Accuracy 098.74% | Test Accuracy 097.15%\n",
      "@Epoch 160: Train Accuracy 099.95% | Test Accuracy 097.65%\n",
      "@Epoch 200: Train Accuracy 100.00% | Test Accuracy 097.68%\n",
      "@Epoch 240: Train Accuracy 100.00% | Test Accuracy 097.77%\n",
      "@Epoch 280: Train Accuracy 100.00% | Test Accuracy 097.81%\n",
      "@Epoch 320: Train Accuracy 100.00% | Test Accuracy 097.84%\n",
      "@Epoch 360: Train Accuracy 100.00% | Test Accuracy 097.85%\n",
      "@Epoch 399: Train Accuracy 100.00% | Test Accuracy 097.84%\r"
     ]
    }
   ],
   "source": [
    "# Operations to compute the running mean and variance.\n",
    "# ----------------------------------------------------\n",
    "# In general, *tf.GraphKeys*, is a collection of names\n",
    "# to collect and retrieve values associated with a graph\n",
    "extra_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "model_path = \"tfmodels/ffnn_v05.ckpt\"\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run([train_step, extra_ops], feed_dict={X: X_train, y: y_train,\n",
    "                                                     training: True})\n",
    "        acc, bn_train_acc = sess.run([accuracy, tb_acc], feed_dict={X: X_train, y:y_train})\n",
    "        cvacc, bn_cv_acc = sess.run([accuracy, tb_acc], feed_dict={X: X_test, y:y_test})\n",
    "        tb_train_writer.add_summary(bn_train_acc, epoch)\n",
    "        tb_cv_writer.add_summary(bn_cv_acc, epoch)\n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch:03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)\n",
    "    saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Restoring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tfmodels/ffnn_v05.ckpt\n",
      "@Epoch 000: Train Accuracy 100.00% | Test Accuracy 097.84%\n",
      "@Epoch 010: Train Accuracy 100.00% | Test Accuracy 097.84%\n",
      "@Epoch 020: Train Accuracy 100.00% | Test Accuracy 097.83%\n",
      "@Epoch 030: Train Accuracy 100.00% | Test Accuracy 097.83%\n",
      "@Epoch 039: Train Accuracy 100.00% | Test Accuracy 097.85%\r"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = tf.train.import_meta_graph(\"./tfmodels/ffnn_v05.ckpt.meta\")\n",
    "new_model = tf.train.Saver()\n",
    "new_model_path = \"./tfmodels/ffnn_v05_1.ckpt\"\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "training = tf.get_default_graph().get_tensor_by_name(\"training_bool:0\")\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"metrics/accuracy:0\")\n",
    "train_step = tf.get_default_graph().get_operation_by_name(\"train/train_step\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "bn_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "epochs = 40\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    model.restore(sess, \"./tfmodels/ffnn_v05.ckpt\")\n",
    "    for epoch in range(epochs):\n",
    "        sess.run([train_step, bn_ops], feed_dict={X: X_train, y: y_train,\n",
    "                                                  training: True})\n",
    "        acc = sess.run(accuracy, feed_dict={X: X_train, y: y_train})\n",
    "        cvacc = sess.run(accuracy, feed_dict={X: X_test, y: y_test})\n",
    "        end = \"\\n\" if epoch % 10 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch:03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)\n",
    "    new_model.save(sess, new_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "----\n",
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice, seed\n",
    "from functools import partial\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_train_0_4 = y_train < 5\n",
    "y_0_4_train = y_train[map_train_0_4] \n",
    "X_0_4_train = X_train[map_train_0_4,:]\n",
    "\n",
    "map_test_0_4 = y_test < 5\n",
    "y_0_4_test = y_test[map_test_0_4]\n",
    "X_0_4_test = X_test[map_test_0_4, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning V.01\n",
    "We being by training a feed-forward neural network with 5 hidden layers, elu activation function and he initializiation. In order to train this NNet, we consider Adam optimization and early stopping.\n",
    "\n",
    "For educational purposes, we will consider the test-set as the validation set. Early stopping will kick in once the accuracy on the validation (test) set at epoch $t$ drops below the accuracy at epoch $t-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "logs = \"./tf_logs/transfer/ffnn_0_4\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_output = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "he_init = variance_scaling_initializer()\n",
    "\n",
    "hidden_layer = partial(tf.layers.dense, units=n_hidden,\n",
    "                       activation=tf.nn.elu,\n",
    "                       kernel_initializer=he_init)\n",
    "\n",
    "with tf.name_scope(\"DNN\"):\n",
    "    for hi in range(1, 6):\n",
    "        if hi == 1:\n",
    "            hidden = hidden_layer(inputs=X, name=f\"hidden_{hi}\")\n",
    "        else:\n",
    "            hidden = hidden_layer(inputs=hidden, name=f\"hidden_{hi}\")\n",
    "\n",
    "    output = hidden_layer(inputs=hidden, units=n_output,\n",
    "                          activation=None, name=\"output\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=output)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss, name=\"train_step\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    ### Writer Configuration ###\n",
    "    writer_train = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    writer_test = tf.summary.FileWriter(logs + \"/test\", tf.get_default_graph())\n",
    "    writer_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "model_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch @000, Train Acc: 059.83% | Test Acc: 060.54% | ∆%: 100.0000% | Test loss: 104.697% |\n",
      "At epoch @040, Train Acc: 097.60% | Test Acc: 098.02% | ∆%: 001.9482% | Test loss: 006.743% | Stag: *\n",
      "At epoch @118, Train Acc: 099.70% | Test Acc: 098.87% | ∆%: 001.6510% | Test loss: 004.014% | Stag: ******\n",
      "At epoch @119, Train Acc: 099.71% | Test Acc: 098.89% | ∆%: 001.8362% | Test loss: 004.021% | Stag: ******\n",
      "At epoch @120, Train Acc: 099.73% | Test Acc: 098.91% | ∆%: 002.3964% | Test loss: 004.044% | Stag: *******\n",
      "At epoch @121, Train Acc: 099.72% | Test Acc: 098.89% | ∆%: 002.7260% | Test loss: 004.057% | Stag: *******\n",
      "At epoch @122, Train Acc: 099.72% | Test Acc: 098.89% | ∆%: 003.9221% | Test loss: 004.104% | Stag: ********\n",
      "At epoch @123, Train Acc: 099.71% | Test Acc: 098.89% | ∆%: 004.9218% | Test loss: 004.143% | Stag: ********\n",
      "At epoch @124, Train Acc: 099.71% | Test Acc: 098.95% | ∆%: 008.4647% | Test loss: 004.283% | Stag: *********\n",
      "At epoch @125, Train Acc: 099.56% | Test Acc: 098.72% | ∆%: 016.8572% | Test loss: 004.615% | Stag: *********\n",
      "At epoch @126, Train Acc: 098.75% | Test Acc: 097.86% | ∆%: 108.2824% | Test loss: 008.225% | Stag: **********\n",
      "At epoch @127, Train Acc: 082.55% | Test Acc: 082.12% | ∆%: 3119.2310% | Test loss: 127.125% | Stag: **********\n",
      "Early Stopping...\n",
      "The loss change rate was of 163.75398%\n"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "current_test_loss = 10 ** 10\n",
    "max_stag_threshold = 20\n",
    "current_stag = 0\n",
    "mean_stag_val = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_0_4_train, y: y_0_4_train})\n",
    "        train_acc, writer_train_acc = sess.run([accuracy, writer_accuracy],\n",
    "                                               feed_dict={X: X_0_4_train, y: y_0_4_train})\n",
    "        test_acc, writer_test_acc = sess.run([accuracy, writer_accuracy],\n",
    "                                              feed_dict={X: X_0_4_test, y: y_0_4_test})\n",
    "        \n",
    "        test_loss = sess.run(loss, feed_dict={X: X_0_4_test, y: y_0_4_test})\n",
    "        # Add elements to summary\n",
    "        writer_test.add_summary(writer_test_acc, global_step=epoch)\n",
    "        writer_train.add_summary(writer_train_acc, global_step=epoch)\n",
    "        # We consider an stagnation if, for 20 steps, the test set does not\n",
    "        # move either way more than 2% from the current value\n",
    "        delta_test_loss = abs(test_loss / current_test_loss - 1)\n",
    "        if delta_test_loss < 0.01 or test_loss > current_test_loss:\n",
    "            if current_stag >= max_stag_threshold:\n",
    "                print(f\"Early Stopping...\\nThe loss change rate was of {mean_stag_val / max_stag_threshold:0.5%}\")\n",
    "                break\n",
    "            else:\n",
    "                current_stag += 1\n",
    "                mean_stag_val += delta_test_loss\n",
    "                end = \"\\n\" if current_stag > 10 else \"\\r\"\n",
    "                print((f\"At epoch @{epoch:03}, Train Acc: {train_acc:07.02%} \"\n",
    "                       f\"| Test Acc: {test_acc:07.02%} | ∆%: {delta_test_loss:09.4%} \"\n",
    "                       f\"| Test loss: {test_loss:08.3%} | Stag: {'*' * ceil(current_stag / 2)}\"), end=end)\n",
    "        else:\n",
    "            current_stag = 0\n",
    "            mean_stag_val = 0\n",
    "            end = \"\\n\" if epoch % 20 == 0 else \"\\r\"\n",
    "            print((f\"At epoch @{epoch:03}, Train Acc: {train_acc:07.02%} \"\n",
    "                   f\"| Test Acc: {test_acc:07.02%} | ∆%: {delta_test_loss:09.4%} \"\n",
    "                   f\"| Test loss: {test_loss:08.3%} |\"), end=end)\n",
    "            current_test_loss = test_loss\n",
    "\n",
    "    model_saver.save(sess, \"./tfmodels/nnet_0_4_v01.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
