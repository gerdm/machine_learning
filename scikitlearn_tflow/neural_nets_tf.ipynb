{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks With TensorFlow\n",
    "## Stable implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import variance_scaling_initializer # He-initializer\n",
    "from jupyter_tf_graph import show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28 * 28) / 255.0\n",
    "X_test = X_test.reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Fully Connected Deep Neural Network\n",
    "### FFNN V.01\n",
    "Feed forward neural network with sigmoid activation function and Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v01\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, activation=tf.nn.sigmoid, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.sigmoid, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.sigmoid, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.sigmoid, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.sigmoid, name=\"hidden5\")\n",
    "    outputs = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=outputs\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  40: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  80: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  120: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  160: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  200: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  240: Train Accuracy 009.87% | Test Accuracy 009.80%\n",
      "@Epoch  280: Train Accuracy 011.24% | Test Accuracy 011.35%\n",
      "@Epoch  320: Train Accuracy 011.24% | Test Accuracy 011.35%\n",
      "@Epoch  360: Train Accuracy 011.24% | Test Accuracy 011.35%\n",
      "CPU times: user 24min 36s, sys: 4min 15s, total: 28min 51s%\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_test, y: y_test})\n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### FFNN V.02\n",
    "Feed forward neural network with elu activation function and Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v02\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, activation=tf.nn.elu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.elu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.elu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.elu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.elu, name=\"hidden5\")\n",
    "    outputs = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=outputs\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 006.13% | Test Accuracy 006.11%\n",
      "@Epoch  40: Train Accuracy 009.70% | Test Accuracy 009.56%\n",
      "@Epoch  80: Train Accuracy 014.78% | Test Accuracy 014.49%\n",
      "@Epoch  120: Train Accuracy 021.02% | Test Accuracy 021.13%\n",
      "@Epoch  160: Train Accuracy 027.68% | Test Accuracy 028.32%\n",
      "@Epoch  200: Train Accuracy 033.88% | Test Accuracy 034.71%\n",
      "@Epoch  240: Train Accuracy 039.29% | Test Accuracy 040.41%\n",
      "@Epoch  280: Train Accuracy 043.42% | Test Accuracy 044.78%\n",
      "@Epoch  320: Train Accuracy 047.05% | Test Accuracy 048.85%\n",
      "@Epoch  360: Train Accuracy 050.14% | Test Accuracy 051.77%\n",
      "CPU times: user 26min 10s, sys: 4min 11s, total: 30min 22s%\n",
      "Wall time: 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy], feed_dict={X: X_test, y: y_test})\n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### FFNN V.03\n",
    "Feed forward neural network with elu activation function and ADAM Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v03\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=None, name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden, activation=tf.nn.elu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden, activation=tf.nn.elu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden, activation=tf.nn.elu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden, activation=tf.nn.elu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden, activation=tf.nn.elu, name=\"hidden5\")\n",
    "    outputs = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=outputs\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(outputs, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 025.93% | Test Accuracy 026.65%\n",
      "@Epoch  40: Train Accuracy 091.63% | Test Accuracy 091.74%\n",
      "@Epoch  80: Train Accuracy 094.57% | Test Accuracy 094.37%\n",
      "@Epoch  120: Train Accuracy 096.32% | Test Accuracy 095.71%\n",
      "@Epoch  160: Train Accuracy 097.35% | Test Accuracy 096.45%\n",
      "@Epoch  200: Train Accuracy 098.10% | Test Accuracy 096.92%\n",
      "@Epoch  240: Train Accuracy 098.75% | Test Accuracy 097.19%\n",
      "@Epoch  280: Train Accuracy 098.96% | Test Accuracy 097.31%\n",
      "@Epoch  320: Train Accuracy 099.46% | Test Accuracy 097.39%\n",
      "@Epoch  360: Train Accuracy 099.69% | Test Accuracy 097.42%\n",
      "CPU times: user 26min 11s, sys: 4min 17s, total: 30min 28s%\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy],\n",
    "                               feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy],\n",
    "                                   feed_dict={X: X_test, y: y_test})\n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### FFNN V.04\n",
    "Feed forward neural network with elu activation function, ADAM Optimizer and Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "logs = \"./tf_logs/ffnn_v04/\"\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "eta = 0.9\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    z1 = tf.layers.dense(X, n_hidden, name=\"z1\")\n",
    "    z1_bn = tf.layers.batch_normalization(z1, training=training, momentum=eta)\n",
    "    a1 = tf.nn.elu(z1_bn)\n",
    "    \n",
    "    z2 = tf.layers.dense(a1, n_hidden, name=\"z2\")\n",
    "    z2_bn = tf.layers.batch_normalization(z2, training=training, momentum=eta)\n",
    "    a2 = tf.nn.elu(z2_bn)\n",
    "    \n",
    "    z3 = tf.layers.dense(a2, n_hidden, name=\"z3\")\n",
    "    z3_bn = tf.layers.batch_normalization(z3, training=training, momentum=eta)\n",
    "    a3 = tf.nn.elu(z3_bn)\n",
    "    \n",
    "    z4 = tf.layers.dense(a3, n_hidden, name=\"z4\")\n",
    "    z4_bn = tf.layers.batch_normalization(z4, training=training, momentum=eta)\n",
    "    a4 = tf.nn.elu(z4)\n",
    "    \n",
    "    z5 = tf.layers.dense(a4, n_hidden, name=\"z5\")\n",
    "    z5_bn = tf.layers.batch_normalization(z5, training=training, momentum=eta)\n",
    "    a5 = tf.nn.elu(z5_bn)\n",
    "    \n",
    "    output = tf.layers.dense(a5, n_hidden, name=\"output\")\n",
    "\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y,\n",
    "        logits=output\n",
    "    )\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "    \n",
    "alpha = 0.001\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.AdamOptimizer(alpha)\n",
    "    train_step = optimizer.minimize(loss)\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"metrics\"):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    tb_train_writer = tf.summary.FileWriter(logs + \"/train\", tf.get_default_graph())\n",
    "    tb_cv_writer = tf.summary.FileWriter(logs + \"/cv\", tf.get_default_graph())\n",
    "    tb_accuracy = tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch  00: Train Accuracy 005.91% | Test Accuracy 005.43%\n",
      "@Epoch  40: Train Accuracy 091.78% | Test Accuracy 092.06%\n",
      "@Epoch  80: Train Accuracy 095.16% | Test Accuracy 094.87%\n",
      "@Epoch  120: Train Accuracy 096.90% | Test Accuracy 096.05%\n",
      "@Epoch  160: Train Accuracy 097.95% | Test Accuracy 096.75%\n",
      "@Epoch  200: Train Accuracy 098.79% | Test Accuracy 097.07%\n",
      "@Epoch  240: Train Accuracy 099.32% | Test Accuracy 097.29%\n",
      "@Epoch  280: Train Accuracy 099.68% | Test Accuracy 097.37%\n",
      "@Epoch  320: Train Accuracy 099.87% | Test Accuracy 097.45%\n",
      "@Epoch  360: Train Accuracy 099.95% | Test Accuracy 097.43%\n",
      "CPU times: user 47min 35s, sys: 6min 25s, total: 54min7.43%\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "epochs = 400\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        sess.run([train_step, extra_update_ops], feed_dict={training: True, X: X_train, y: y_train})\n",
    "        acc, tb_acc = sess.run([accuracy, tb_accuracy],\n",
    "                               feed_dict={X: X_train, y: y_train})\n",
    "        cvacc, tb_cvacc = sess.run([accuracy, tb_accuracy],\n",
    "                                    feed_dict={X: X_test, y: y_test})\n",
    "        \n",
    "        tb_train_writer.add_summary(tb_acc, epoch)\n",
    "        tb_cv_writer.add_summary(tb_cvacc, epoch)\n",
    "        \n",
    "        end = \"\\n\" if epoch % 40 == 0 else \"\\r\"\n",
    "        print(f\"@Epoch {epoch: 03}: Train Accuracy {acc:07.2%} | Test Accuracy {cvacc:07.2%}\",\n",
    "              end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network Version Comparison\n",
    "![FFNNs Comparisson](./images/ffnn_vs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing and Reusing TF Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def a_plus_b(a, b): return a + b\n",
    "a_plus_3 = partial(a_plus_b, b=3)\n",
    "a_plus_3(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden = 100\n",
    "n_output = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(n_inputs, None), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=None, name=\"y\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name=\"training\")\n",
    "\n",
    "batch_norm = partial()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
