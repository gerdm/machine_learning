{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d141de91-bf9d-44e6-b993-bb784587696c",
    "_uuid": "96f615e02ee6de6ddb9d3f85e3affd4fe636f002"
   },
   "source": [
    "# Intro to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from numpy.random import seed, shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "001abf7d-b936-4cf5-a807-10a7c8bc7df0",
    "_uuid": "a770a6a8638c467001263bff555142c8ff063c6b"
   },
   "source": [
    "**My first computation Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# Defining a graph (a default graph)\n",
    "# Every declared node is automatically added \n",
    "# to the 'default-graph'\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(5, name=\"y\")\n",
    "f = x * x * y + y + 2\n",
    "# Run the graph inside a session.\n",
    "# With the 'with' command, the session is set as the\n",
    "# default sesion\n",
    "with tf.Session() as sess:\n",
    "    # We need to initialize the variables before\n",
    "    # performing operations using them\n",
    "    x.initializer.run() # Equivalent to: tf.get_default_session().run(x.initializer)\n",
    "    y.initializer.run() # Equivalent to: tf.get_default_session().run(y.initializer)\n",
    "    result = f.eval()   # Equivalent to: tf.get_default_session().run(f)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "338b90a2-bc73-4f4d-bba4-1a0faebee202",
    "_uuid": "a149a0d1c964cbc0c6899d0415590dd2b9a2381f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# Removing every node inside the\n",
    "# default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# **CONSTRUCTION PHASE**\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(5, name=\"y\")\n",
    "f = x * x * y + y + 2\n",
    "# Add to the graph a step to initialize all variables\n",
    "# (we are not actually initializing the variables in this step)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# **EXECUTION PHASE**\n",
    "with tf.Session() as ses:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b2f81670-4bcb-4eb0-b2cc-8c4086b681c2",
    "_uuid": "2a4e49456415951dc2444caec922e0aa8bef091a"
   },
   "source": [
    "### Evaluating nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "e25499c1-fb86-4a68-a4bb-089f7ed6e3cb",
    "_uuid": "520a411549831ee1c2bb61102de782b9723bb3d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "\n",
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Whenever we evaluate a node, Tensorflow automatically\n",
    "# determines the set of nodes that it depends on.\n",
    "\n",
    "w  = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# **The ineficient way to evaluate a set of nodes**\n",
    "# By evaluating (y, z) (nodes) the following way, TensorFlow\n",
    "# has to compute 'w' and 'x' twice in order to obtain (x, z)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(y.eval())\n",
    "    print(z.eval())\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "w  = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "print()\n",
    "init = tf.global_variables_initializer()\n",
    "# **The proper way to evaluate a set of nodes**\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    xres, yres = sess.run([y, z])\n",
    "    print(xres)\n",
    "    print(yres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2f311a6-a51e-4fe2-af22-34d940d730cc",
    "_uuid": "09e054b3fe9210414fc815e7e56cbe5196f65bd9"
   },
   "source": [
    "Operations in TensorFlow are called *ops*, `tf.constant` and `tf.Variable` are called *source ops* since they take no input. *Ops* with $n$ inputs and $m$ outputs are called *tensors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f1add54c-3430-45ea-b6f4-fb234d8d8896",
    "_uuid": "7f09c7db5d86a04ea651dc5561ad4dee57d87550"
   },
   "source": [
    "### Computing $\\theta^\\star$ with the normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "f3980145-8037-4f84-aa91-0dc149911f35",
    "_uuid": "13218dd14974bd75a0ab087e382d5c1e451b903f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]\n",
      "[[ -3.60324050e+06]\n",
      " [ -4.29331445e+04]\n",
      " [ -4.26845234e+04]\n",
      " [  1.15434619e+03]\n",
      " [ -8.20419979e+00]\n",
      " [  1.13781357e+02]\n",
      " [ -3.83973656e+01]\n",
      " [  4.75008698e+01]\n",
      " [  4.02665078e+04]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "housing = pd.read_csv(\"./datasets/housing.csv\").dropna()\n",
    "m, n = housing.shape\n",
    "housing_data_bias = np.c_[np.ones((m, 1)), housing.drop([\"ocean_proximity\", \"median_house_value\"], axis=1).values]\n",
    "housing_target = housing.median_house_value.values.reshape(-1, 1)\n",
    "\n",
    "# Defining the computation graph \n",
    "X = tf.constant(housing_data_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing_target, dtype=tf.float32, name=\"y\")\n",
    "Xtranspose = tf.transpose(X)\n",
    "theta = tf.matrix_inverse(Xtranspose @ X) @ Xtranspose @ y\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print(sess.list_devices())\n",
    "    theta_star = theta.eval() # Equivalent to sess.run(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2db47547-c58e-43b6-b34c-d29dc7d61dde",
    "_uuid": "67630970e5a58295f0da3023bb31410b2ff7f53a"
   },
   "source": [
    "### Computing $\\theta^\\star$ with Gradient Descent\n",
    "#### Manually Setting the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "e4744113-5c34-4859-a983-aa5e742b40b1",
    "_uuid": "751ae2e3ed8bd5eca6546dcd48ce685d28f7221f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 56,117,448,704.00\n",
      "@Epoch 100, MSE: 47,701,590,016.00\n",
      "@Epoch 200, MSE: 47,639,318,528.00\n",
      "@Epoch 300, MSE: 47,633,567,744.00\n",
      "@Epoch 400, MSE: 47,632,191,488.00\n",
      "@Epoch 500, MSE: 47,631,593,472.00\n",
      "@Epoch 600, MSE: 47,631,310,848.00\n",
      "@Epoch 700, MSE: 47,631,142,912.00\n",
      "@Epoch 800, MSE: 47,631,052,800.00\n",
      "@Epoch 900, MSE: 47,630,999,552.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing_data_bias_scaled = StandardScaler().fit_transform(housing_data_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "X = tf.constant(housing_data_bias_scaled, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.median_house_value.values.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE\")\n",
    "# **Taking a step of gradient descent**\n",
    "# ---------------- Manual Differentiation----------------\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "# Updating the parameters\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "# ---------------- Manual Differentiation----------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 1) Initialize all variables\n",
    "    sess.run(init)\n",
    "    # Step 2) Iterate over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval():0,.2f}\")\n",
    "        # update the training operation: compute gradients\n",
    "        sess.run(training_op)\n",
    "    theta_star = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2db47547-c58e-43b6-b34c-d29dc7d61dde",
    "_uuid": "67630970e5a58295f0da3023bb31410b2ff7f53a"
   },
   "source": [
    "### Computing $\\theta^\\star$ with Gradient Descent\n",
    "#### Using automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "932de405-2061-4366-ad6a-bdd721907c96",
    "_uuid": "cd6350ae680df9075871658a1519552ac13e0e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 56,117,559,296.00\n",
      "@Epoch 100, MSE: 47,701,585,920.00\n",
      "@Epoch 200, MSE: 47,639,318,528.00\n",
      "@Epoch 300, MSE: 47,633,567,744.00\n",
      "@Epoch 400, MSE: 47,632,191,488.00\n",
      "@Epoch 500, MSE: 47,631,593,472.00\n",
      "@Epoch 600, MSE: 47,631,306,752.00\n",
      "@Epoch 700, MSE: 47,631,142,912.00\n",
      "@Epoch 800, MSE: 47,631,052,800.00\n",
      "@Epoch 900, MSE: 47,630,999,552.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing_data_bias_scaled = StandardScaler().fit_transform(housing_data_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "X = tf.constant(housing_data_bias_scaled, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.median_house_value.values.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "# Initializing the parameters to learn\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE\")\n",
    "# **Taking a step of gradient descent**\n",
    "# ---------------- Automatic Differentiation----------------\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "# ---------------- Automatic Differentiation----------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 1) Initialize all variables\n",
    "    sess.run(init)\n",
    "    # Step 2) Iterate over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval():0,.2f}\")\n",
    "        # update the training operation: comppute gradients\n",
    "        sess.run(training_op)\n",
    "    theta_star = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2db47547-c58e-43b6-b34c-d29dc7d61dde",
    "_uuid": "67630970e5a58295f0da3023bb31410b2ff7f53a"
   },
   "source": [
    "### Computing $\\theta^\\star$ with Gradient Descent\n",
    "#### Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "a2359d21-1389-4a12-b745-443cb4b14c7e",
    "_uuid": "d05aa937551a5e50aa576086ef53e6fd9bea4b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 56,117,612,544.00\n",
      "@Epoch 100, MSE: 47,701,594,112.00\n",
      "@Epoch 200, MSE: 47,639,330,816.00\n",
      "@Epoch 300, MSE: 47,633,571,840.00\n",
      "@Epoch 400, MSE: 47,632,187,392.00\n",
      "@Epoch 500, MSE: 47,631,601,664.00\n",
      "@Epoch 600, MSE: 47,631,306,752.00\n",
      "@Epoch 700, MSE: 47,631,142,912.00\n",
      "@Epoch 800, MSE: 47,631,052,800.00\n",
      "@Epoch 900, MSE: 47,631,003,648.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing_data_bias_scaled = StandardScaler().fit_transform(housing_data_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "X = tf.constant(housing_data_bias_scaled, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.median_house_value.values.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE\")\n",
    "# **Taking a step of gradient descent**\n",
    "# ---------------- TF Optimizer ----------------\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "# ---------------- TF Optimizer ----------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 1) Initialize all variables\n",
    "    sess.run(init)\n",
    "    # Step 2) Iterate over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval():0,.2f}\")\n",
    "        # update the training operation: comppute gradients\n",
    "        sess.run(training_op)\n",
    "    theta_star = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d2598f2-ba37-48f3-b487-0f7ef6406189",
    "_uuid": "04565e08879092c892ac6bf1b2b7d6945c6cb6d0"
   },
   "source": [
    "----\n",
    "### Computing $\\theta^\\star$ with Mini-Batch Gradient Descent\n",
    "#### The use of Placeholders for model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(n_batches, set_seed=None):\n",
    "    \"\"\"\n",
    "    Retrieve the i-th batch from a random shuffled\n",
    "    training dataset. Each epoch the training\n",
    "    dataset gets reshuffled.\n",
    "    \"\"\"\n",
    "    seed(set_seed)\n",
    "    batches = np.c_[housing_data_bias_scaled, housing_target]\n",
    "    shuffle(batches)\n",
    "    batches = np.array_split(batches, n_batches)\n",
    "    for batch in batches:\n",
    "        yield batch[:, :-1], batch[:, -1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "9bef903a-b472-4a3f-9d3b-b6e2f8985503",
    "_uuid": "36861c7ed1129cb749f9c3fab8e2963db5b84ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 49,532,694,528.00\n",
      "@Epoch 100, MSE: 46,844,346,368.00\n",
      "@Epoch 200, MSE: 47,022,866,432.00\n",
      "@Epoch 300, MSE: 47,475,621,888.00\n",
      "@Epoch 400, MSE: 47,403,696,128.00\n",
      "@Epoch 500, MSE: 47,448,813,568.00\n",
      "@Epoch 600, MSE: 46,916,739,072.00\n",
      "@Epoch 700, MSE: 47,627,169,792.00\n",
      "@Epoch 800, MSE: 47,496,564,736.00\n",
      "@Epoch 900, MSE: 47,253,815,296.00\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 5000\n",
    "n_epochs = 1000\n",
    "n_batches = ceil(m / batch_size)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n - 1], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta)\n",
    "err = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(err), name=\"MSE\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in fetch_batch(n_batches, set_seed=epoch):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval(feed_dict={X: X_batch, y: y_batch}):0,.2f}\")\n",
    "    theta_star_bgd = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d2598f2-ba37-48f3-b487-0f7ef6406189",
    "_uuid": "04565e08879092c892ac6bf1b2b7d6945c6cb6d0"
   },
   "source": [
    "----\n",
    "### Saving and restoring models\n",
    "#### *Saving a file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "9bef903a-b472-4a3f-9d3b-b6e2f8985503",
    "_uuid": "36861c7ed1129cb749f9c3fab8e2963db5b84ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 49,532,710,912.00\n",
      "@Epoch 100, MSE: 46,844,350,464.00\n",
      "@Epoch 200, MSE: 47,022,866,432.00\n",
      "@Epoch 300, MSE: 47,475,621,888.00\n",
      "@Epoch 400, MSE: 47,403,692,032.00\n",
      "@Epoch 500, MSE: 47,448,813,568.00\n",
      "@Epoch 600, MSE: 46,916,739,072.00\n",
      "@Epoch 700, MSE: 47,627,169,792.00\n",
      "@Epoch 800, MSE: 47,496,564,736.00\n",
      "@Epoch 900, MSE: 47,253,815,296.00\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 5000\n",
    "n_epochs = 1000\n",
    "n_batches = ceil(m / batch_size)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n - 1], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta)\n",
    "err = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(err), name=\"MSE\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in fetch_batch(n_batches):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            # Checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess, \"./tmp/linear_regression.ckpt\")\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval(feed_dict={X: X_batch, y: y_batch}):0,.2f}\")\n",
    "    theta_star_bgd = theta.eval()\n",
    "    save_path = saver.save(sess, \"./tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d2598f2-ba37-48f3-b487-0f7ef6406189",
    "_uuid": "04565e08879092c892ac6bf1b2b7d6945c6cb6d0"
   },
   "source": [
    "----\n",
    "### Saving and restoring models\n",
    "#### *Restoring a File*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/my_model_final.ckpt\n",
      "@Epoch 000, MSE: 47,592,103,936.00\n",
      "@Epoch 100, MSE: 47,399,989,248.00\n",
      "@Epoch 200, MSE: 47,747,645,440.00\n",
      "@Epoch 300, MSE: 47,565,201,408.00\n",
      "@Epoch 400, MSE: 48,000,819,200.00\n",
      "@Epoch 500, MSE: 47,279,427,584.00\n",
      "@Epoch 600, MSE: 47,240,843,264.00\n",
      "@Epoch 700, MSE: 47,740,170,240.00\n",
      "@Epoch 800, MSE: 47,980,371,968.00\n",
      "@Epoch 900, MSE: 48,388,489,216.00\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=[None, n - 1], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1 ], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"y_pred\")\n",
    "mse = tf.reduce_mean(tf.square(y_pred - y), name=\"MSE\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./tmp/my_model_final.ckpt\")\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in fetch_batch(n_batches):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            # Checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess, \"./tmp/linear_regression.ckpt\")\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval(feed_dict={X: X_batch, y: y_batch}):0,.2f}\")\n",
    "    theta_star_bgd = theta.eval()\n",
    "    save_path = saver.save(sess, \"./tmp/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 23,291,740,160.00\n",
      "@Epoch 100, MSE: 36,742,144,000.00\n",
      "@Epoch 200, MSE: 45,800,816,640.00\n",
      "@Epoch 300, MSE: 43,153,838,080.00\n",
      "@Epoch 400, MSE: 51,082,092,544.00\n",
      "@Epoch 500, MSE: 43,747,704,832.00\n",
      "@Epoch 600, MSE: 33,567,025,152.00\n",
      "@Epoch 700, MSE: 38,498,402,304.00\n",
      "@Epoch 800, MSE: 46,691,311,616.00\n",
      "@Epoch 900, MSE: 1,822,485,905,408.00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "learning_rate = 0.1\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root = \"tf_logs\"\n",
    "logdir = f\"{root}/run-{now}\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "batch_size = 5000\n",
    "n_epochs = 1000\n",
    "n_batches = ceil(m / batch_size)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n - 1], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta)\n",
    "# Name scope: To group relating nodes into a single\n",
    "# *graphical* node\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    err = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(err), name=\"MSE\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in fetch_batch(n_epochs):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            if batch_ix % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y:y_batch})\n",
    "                step = epoch * n_batches + batch_ix\n",
    "                file_writer.add_summary(summary_str, step )\n",
    "        if epoch % 100 == 0:\n",
    "            # Checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess, \"./tmp/linear_regression.ckpt\")\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval(feed_dict={X: X_batch, y: y_batch}):0,.2f}\")\n",
    "    theta_star_bgd = theta.eval()\n",
    "    save_path = saver.save(sess, \"./tmp/my_model_final.ckpt\")\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root = \"tf_logs\"\n",
    "logdir = f\"{root}/run-{now}\"\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0., name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_features], name=\"X\")\n",
    "relus = [relu(X) for _ in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root = \"tf_logs\"\n",
    "logdir = f\"{root}/run-{now}\"\n",
    "\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0., name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_features], name=\"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                                initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for _ in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the main benefits of creating a computation graph rather than directly executing the computations? What are the main drawbacks?**  \n",
    "Creating a computation graph allows us to run operations in parallel across CPUs and GPUs; its main drawback is the lack of instantaneously evaluating any node to see its output, we need to execute the graph in order to do so.\n",
    "\n",
    "**2. Is the statment `a_val = a.eval(session=sess)` equivalent to `a_val = sess.run(a)`?**  \n",
    "Yes, since both operations run under the same session and execute the computation graph in the exact same way.\n",
    "\n",
    "**3. Is the statement `a_val, b_val = a.eval(session.sess), b.eval(session.sess)` equivalent to `a_val, b_val = sess.run([a, b])`?**  \n",
    "No, the first statement runs the graph two times: values affecting both `a` and `b` must be computed twice in order to reach an output; the second statement, on the other hand, evaluates both `a` and `b` in paralell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Can you run two graphs in the same session?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running graph1 10\n",
      "Running graph2 10\n"
     ]
    }
   ],
   "source": [
    "graph1 = tf.Graph()\n",
    "with graph1.as_default():\n",
    "    x1 = tf.Variable(3, name=\"x1\")\n",
    "    y1 = tf.Variable(1, name=\"x2\")\n",
    "    z1 = x1 * x1 + y1\n",
    "    init1 = tf.global_variables_initializer()\n",
    "\n",
    "graph2 = tf.Graph()\n",
    "with graph2.as_default():\n",
    "    x2 = tf.Variable(3, name=\"x2\")\n",
    "    y2 = tf.Variable(1, name=\"y2\")\n",
    "    z2 = x2 * x2 + y2\n",
    "    init2 = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session(graph=graph1) as sess:\n",
    "    sess.run(init1)\n",
    "    print(f\"Running graph1 {z1.eval()}\")\n",
    "    \n",
    "with tf.Session(graph=graph2) as sess:\n",
    "    sess.run(init2)\n",
    "    print(f\"Running graph2 {z2.eval()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to run two graphs in a session will results in an error since `tf.Session` takes a single graph as a parameter. Therefore, it is **not** possible to run two graphs in a same session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. If you create a graph `g` containing a variable `w`, then start two threads and open a session in each thread, both using the same graph `g`, will each session have its own copy of the variable `w` or will it be shared?**  \n",
    "Each session will have its own copy of `w`, since all `g` does is to define what will happen once (any) session runs that graph.\n",
    "\n",
    "**6. When is a variable initialized? When is it destroyed?**  \n",
    "A variable is initialized when its initializer is run, and it is destroyed when the session is closed.\n",
    "\n",
    "**7. What is the difference between a placeholder and a variable?**\n",
    "A placeholder, as the name suggests, is a TensorFlow object that will recieve some input during the execution phase. On the other hand, a variable is a TensorFlow object which we will modify as the session runs.\n",
    "\n",
    "Another way to think about it is that a placeholder will store $X$, for which we only know its shape but not how many training instances and the instances themselves, and a variable will store $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. What happens when you run the graph to evaluate an operation that depends on a placeholder but you don't feed its value? What happens if the operations does not depend on the placeholder?**  \n",
    "TensorFlow raisses an error if an operation that depends on a placeholder is not fed; if the operation does not depend on the placeholder, there is no data to feed, therefore, no error gets raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(shape=None, dtype=tf.float32)\n",
    "fx = tf.pow(x, 2)\n",
    "\n",
    "train_val = 3\n",
    "with tf.Session() as sess:\n",
    "    # *** Raises and error if feed_dict is not provided ***\n",
    "    fx_val = sess.run(fx, feed_dict={x: train_val})\n",
    "    print(fx_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. When you run a graph, can you feed the output value of any operation, or just the value of placeholders?**  \n",
    "It is possible to feed the output value of any operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running op = x * c. Feeding c:3\n",
      "6.0\n",
      "\n",
      "Running op = x * c. Feeding c:3 & x:10\n",
      "300.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "c = tf.placeholder(tf.float32)\n",
    "x = tf.Variable(2, dtype=tf.float32)\n",
    "op = tf.multiply(c, x, name=\"operation\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    print(\"Running op = x * c. Feeding c:3\")\n",
    "    print(sess.run(op, feed_dict={c:3}), end=\"\\n\\n\")\n",
    "    print(\"Running op = x * c. Feeding c:3 & x:10\")\n",
    "    print(sess.run(op, feed_dict={x: 10, c:30}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. How can you set a variable to any value you want (during the execution phase)?**  \n",
    "Assuming `X` is the variable we want to set a value to, we can set this value (inside a session) as\n",
    "```\n",
    "    sess.run(X, feed_dict{X: val})\n",
    "```\n",
    "\n",
    "**11. How many times does the reverse-mode autodiff need to traverse the graph in order to compute the gradients of the cost function with regard to 10 variables? What about forward-mode autodiff? And symbolic differentiation?**\n",
    "* reverse-mode: 1 time.\n",
    "* symbolic-diff: 10\n",
    "* forward-mode: depends on the number of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. implement Logistic Regression with Mini-bacth Gradient Descent using TensorFlow. Train it and evaluate it on the moons datasets.**\n",
    "\n",
    "   * Define the graph within a `logisitc_regression()` function that can be reused easily\n",
    "   * Save checkpoints using a `Saver` at regular intervals during training, and save the model at the end of training.\n",
    "   * Restore the last checkpoint upon startup if training was interrumpted.\n",
    "   * Define the graph using nice scopes to that the graph looks good in TensorBoard\n",
    "   * Add summaries to visualize the learnning curve in TensorBoard\n",
    "   * Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2313d6a0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "X_moons, y_moons = make_moons(noise=0.1, random_state=1643)\n",
    "y_moons = y_moons.reshape(-1, 1)\n",
    "plt.scatter(*X_moons.T, c=y_moons.ravel(), s=20, cmap=\"Dark2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Logistic regression model using TFlow\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, learning_rate=0.1):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def define_graph(self):\n",
    "        \"\"\"\n",
    "        Defines a logistic graph\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 01: 34.6574\n",
      "Cost at epoch 02: 09.4543\n",
      "Cost at epoch 03: 08.8307\n",
      "Cost at epoch 04: 08.2860\n",
      "Cost at epoch 05: 07.8098\n",
      "Cost at epoch 06: 07.3932\n",
      "Cost at epoch 07: 07.0284\n",
      "Cost at epoch 08: 06.7089\n",
      "Cost at epoch 09: 06.4292\n",
      "Cost at epoch 10: 06.1845\n",
      "Cost at epoch 11: 05.9707\n",
      "Cost at epoch 12: 05.7840\n",
      "Cost at epoch 13: 05.6212\n",
      "Cost at epoch 14: 05.4795\n",
      "Cost at epoch 15: 05.3563\n",
      "Cost at epoch 16: 05.2494\n",
      "Cost at epoch 17: 05.1566\n",
      "Cost at epoch 18: 05.0761\n",
      "Cost at epoch 19: 05.0063\n",
      "Cost at epoch 20: 04.9457\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "learning_rate = 0.5\n",
    "epochs = 20\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "m = X.get_shape().as_list()[1]\n",
    "theta = tf.Variable(tf.zeros((m, 1)), name=\"theta\")\n",
    "y_hat = tf.sigmoid(tf.matmul(X, theta), name=\"y_hat\")\n",
    "err = -tf.reduce_sum(y * tf.log(y_hat))\n",
    "    \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_step = optimizer.minimize(err)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        cec, _ = sess.run([err, training_step], feed_dict={X:X_moons, y:y_moons})\n",
    "        print(f\"Cost at epoch {epoch + 1:02}: {cec:07.4f}\")\n",
    "    theta_star = sess.run(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.46275711],\n",
       "       [  4.36115837]], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_star"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
