{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d141de91-bf9d-44e6-b993-bb784587696c",
    "_uuid": "96f615e02ee6de6ddb9d3f85e3affd4fe636f002"
   },
   "source": [
    "# Intro to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from numpy.random import seed, shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "001abf7d-b936-4cf5-a807-10a7c8bc7df0",
    "_uuid": "a770a6a8638c467001263bff555142c8ff063c6b"
   },
   "source": [
    "**My first computation Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a graph (a default graph)\n",
    "# Every declared node is automatically added \n",
    "# to the 'default-graph'\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(5, name=\"y\")\n",
    "f = x * x * y + y + 2\n",
    "# Run the graph inside a session.\n",
    "# With the 'with' command, the session is set as the\n",
    "# default sesion\n",
    "with tf.Session() as sess:\n",
    "    # We need to initialize the variables before\n",
    "    # performing operations using them\n",
    "    x.initializer.run() # Equivalent to: tf.get_default_session().run(x.initializer)\n",
    "    y.initializer.run() # Equivalent to: tf.get_default_session().run(y.initializer)\n",
    "    result = f.eval()   # Equivalent to: tf.get_default_session().run(f)\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "338b90a2-bc73-4f4d-bba4-1a0faebee202",
    "_uuid": "a149a0d1c964cbc0c6899d0415590dd2b9a2381f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing every node inside the\n",
    "# default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# **CONSTRUCTION PHASE**\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(5, name=\"y\")\n",
    "f = x * x * y + y + 2\n",
    "# Add to the graph a step to initialize all variables\n",
    "# (we are not actually initializing the variables in this step)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# **EXECUTION PHASE**\n",
    "with tf.Session() as ses:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b2f81670-4bcb-4eb0-b2cc-8c4086b681c2",
    "_uuid": "2a4e49456415951dc2444caec922e0aa8bef091a"
   },
   "source": [
    "### Evaluating nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e25499c1-fb86-4a68-a4bb-089f7ed6e3cb",
    "_uuid": "520a411549831ee1c2bb61102de782b9723bb3d3",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Whenever we evaluate a node, Tensorflow automatically\n",
    "# determines the set of nodes that it depends on.\n",
    "\n",
    "w  = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# **The ineficient way to evaluate a set of nodes**\n",
    "# By evaluating (y, z) (nodes) the following way, TensorFlow\n",
    "# has to compute 'w' and 'x' twice in order to obtain (x, z)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(y.eval())\n",
    "    print(z.eval())\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "w  = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "print()\n",
    "init = tf.global_variables_initializer()\n",
    "# **The proper way to evaluate a set of nodes**\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    xres, yres = sess.run([y, z])\n",
    "    print(xres)\n",
    "    print(yres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d2f311a6-a51e-4fe2-af22-34d940d730cc",
    "_uuid": "09e054b3fe9210414fc815e7e56cbe5196f65bd9"
   },
   "source": [
    "Operations in TensorFlow are called *ops*, `tf.constant` and `tf.Variable` are called *source ops* since they take no input. *Ops* with $n$ inputs and $m$ outputs are called *tensors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f1add54c-3430-45ea-b6f4-fb234d8d8896",
    "_uuid": "7f09c7db5d86a04ea651dc5561ad4dee57d87550"
   },
   "source": [
    "#### Computing $\\theta^\\star$ with the normal equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "f3980145-8037-4f84-aa91-0dc149911f35",
    "_uuid": "13218dd14974bd75a0ab087e382d5c1e451b903f"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "housing = pd.read_csv(\"./datasets/housing.csv\").dropna()\n",
    "m, n = housing.shape\n",
    "housing_data_bias = np.c_[np.ones((m, 1)), housing.drop([\"ocean_proximity\", \"median_house_value\"], axis=1).values]\n",
    "housing_target = housing.median_house_value.values.reshape(-1, 1)\n",
    "\n",
    "# Defining the computation graph \n",
    "X = tf.constant(housing_data_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing_target, dtype=tf.float32, name=\"y\")\n",
    "Xtranspose = tf.transpose(X)\n",
    "theta = tf.matrix_inverse(Xtranspose @ X) @ Xtranspose @ y\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    #print(sess.list_devices())\n",
    "    theta_star = theta.eval() # Equivalent to sess.run(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2db47547-c58e-43b6-b34c-d29dc7d61dde",
    "_uuid": "67630970e5a58295f0da3023bb31410b2ff7f53a"
   },
   "source": [
    "### Computing $\\theta^\\star$ with Gradient Descent\n",
    "#### Manually Setting the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e4744113-5c34-4859-a983-aa5e742b40b1",
    "_uuid": "751ae2e3ed8bd5eca6546dcd48ce685d28f7221f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing_data_bias_scaled = StandardScaler().fit_transform(housing_data_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "X = tf.constant(housing_data_bias_scaled, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.median_house_value.values.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE\")\n",
    "# **Taking a step of gradient descent**\n",
    "# ---------------- Manual Differentiation----------------\n",
    "gradients = 2 / m *tf.matmul(tf.transpose(X), error)\n",
    "# Updating the parameters\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "# ---------------- Manual Differentiation----------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 1) Initialize all variables\n",
    "    sess.run(init)\n",
    "    # Step 2) Iterate over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval():0,.2f}\")\n",
    "        # update the training operation: compute gradients\n",
    "        sess.run(training_op)\n",
    "    theta_star = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2db47547-c58e-43b6-b34c-d29dc7d61dde",
    "_uuid": "67630970e5a58295f0da3023bb31410b2ff7f53a"
   },
   "source": [
    "### Computing $\\theta^\\star$ with Gradient Descent\n",
    "#### Using automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "932de405-2061-4366-ad6a-bdd721907c96",
    "_uuid": "cd6350ae680df9075871658a1519552ac13e0e0b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing_data_bias_scaled = StandardScaler().fit_transform(housing_data_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "X = tf.constant(housing_data_bias_scaled, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.median_house_value.values.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE\")\n",
    "# **Taking a step of gradient descent**\n",
    "# ---------------- Automatic Differentiation----------------\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "# Updating the parameters\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "# ---------------- Automatic Differentiation----------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 1) Initialize all variables\n",
    "    sess.run(init)\n",
    "    # Step 2) Iterate over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval():0,.2f}\")\n",
    "        # update the training operation: comppute gradients\n",
    "        sess.run(training_op)\n",
    "    theta_star = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2db47547-c58e-43b6-b34c-d29dc7d61dde",
    "_uuid": "67630970e5a58295f0da3023bb31410b2ff7f53a"
   },
   "source": [
    "### Computing $\\theta^\\star$ with Gradient Descent\n",
    "#### Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "a2359d21-1389-4a12-b745-443cb4b14c7e",
    "_uuid": "d05aa937551a5e50aa576086ef53e6fd9bea4b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 56,117,678,080.00\n",
      "@Epoch 100, MSE: 47,701,598,208.00\n",
      "@Epoch 200, MSE: 47,639,318,528.00\n",
      "@Epoch 300, MSE: 47,633,567,744.00\n",
      "@Epoch 400, MSE: 47,632,191,488.00\n",
      "@Epoch 500, MSE: 47,631,593,472.00\n",
      "@Epoch 600, MSE: 47,631,310,848.00\n",
      "@Epoch 700, MSE: 47,631,142,912.00\n",
      "@Epoch 800, MSE: 47,631,048,704.00\n",
      "@Epoch 900, MSE: 47,630,999,552.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "tf.reset_default_graph()\n",
    "\n",
    "housing_data_bias_scaled = StandardScaler().fit_transform(housing_data_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "X = tf.constant(housing_data_bias_scaled, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.median_house_value.values.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE\")\n",
    "# **Taking a step of gradient descent**\n",
    "# ---------------- TF Optimizer ----------------\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "# ---------------- TF Optimizer ----------------\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 1) Initialize all variables\n",
    "    sess.run(init)\n",
    "    # Step 2) Iterate over epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval():0,.2f}\")\n",
    "        # update the training operation: comppute gradients\n",
    "        sess.run(training_op)\n",
    "    theta_star = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d2598f2-ba37-48f3-b487-0f7ef6406189",
    "_uuid": "04565e08879092c892ac6bf1b2b7d6945c6cb6d0"
   },
   "source": [
    "----\n",
    "### Computing $\\theta^\\star$ with Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "9bef903a-b472-4a3f-9d3b-b6e2f8985503",
    "_uuid": "36861c7ed1129cb749f9c3fab8e2963db5b84ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Epoch 000, MSE: 49,532,719,104.00\n",
      "@Epoch 100, MSE: 46,844,346,368.00\n",
      "@Epoch 200, MSE: 47,022,866,432.00\n",
      "@Epoch 300, MSE: 47,475,621,888.00\n",
      "@Epoch 400, MSE: 47,403,692,032.00\n",
      "@Epoch 500, MSE: 47,448,813,568.00\n",
      "@Epoch 600, MSE: 46,916,739,072.00\n",
      "@Epoch 700, MSE: 47,627,169,792.00\n",
      "@Epoch 800, MSE: 47,496,564,736.00\n",
      "@Epoch 900, MSE: 47,253,815,296.00\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 5000\n",
    "n_epochs = 1000\n",
    "n_batches = ceil(m / batch_size)\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    \"\"\"\n",
    "    Retrieve the ith batch from a random shuffled\n",
    "    training dataset. Each epoch the training\n",
    "    dataset gets reshuffled.\n",
    "    \"\"\"\n",
    "    seed(epoch)\n",
    "    batches = np.c_[housing_data_bias_scaled, housing_target]\n",
    "    shuffle(batches)\n",
    "    batches = np.array_split(batches, n_batches)\n",
    "    batch_ix = batches[batch_index]\n",
    "    return batch_ix[:, :-1], batch_ix[:, -1].reshape(-1, 1)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n - 1], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n - 1, 1], minval=-1, maxval=1), name=\"theta\")\n",
    "\n",
    "y_pred = tf.matmul(X, theta)\n",
    "err = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(err), name=\"MSE\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_ix in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_ix, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            # Evaluate current mse variable\n",
    "            print(f\"@Epoch {epoch:03}, MSE: {mse.eval(feed_dict={X: X_batch, y: y_batch}):0,.2f}\")\n",
    "    theta_star_bgd = theta.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
