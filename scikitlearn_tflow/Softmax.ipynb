{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydataset import data\n",
    "from pandas import get_dummies\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species_setosa</th>\n",
       "      <th>Species_versicolor</th>\n",
       "      <th>Species_virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species_setosa  \\\n",
       "1           5.1          3.5           1.4          0.2               1   \n",
       "2           4.9          3.0           1.4          0.2               1   \n",
       "3           4.7          3.2           1.3          0.2               1   \n",
       "4           4.6          3.1           1.5          0.2               1   \n",
       "5           5.0          3.6           1.4          0.2               1   \n",
       "\n",
       "   Species_versicolor  Species_virginica  \n",
       "1                   0                  0  \n",
       "2                   0                  0  \n",
       "3                   0                  0  \n",
       "4                   0                  0  \n",
       "5                   0                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = get_dummies(data(\"iris\"))\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.iloc[:,:4].values, iris.iloc[:,4:].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2)\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "X_test = X_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix of size nfeaturesXnclasses to hold the parameters\n",
    "# of each class\n",
    "nfeatures = X_train.shape[0]\n",
    "nclasses = y_train.shape[0]\n",
    "theta = np.zeros((nfeatures, nclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 120)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 120)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix of size nfeatures X nexamples containing the\n",
    "# numerator of sigmoid-softmax function\n",
    "Svals = np.exp(theta.T @ X_train)\n",
    "# Column vector with cnexamples elements containing the normalization\n",
    "# factor for the sigmoid-softmax activation function\n",
    "onesvect = np.ones((1, nclasses))\n",
    "Svalstot = onesvect @ Svals\n",
    "Svalstot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 120)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability for each example to belong to a class 'k'.\n",
    "# Each row corresponds to a class and each column to a given\n",
    "# training example\n",
    "sigsoftk = Svals / Svalstot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 120)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigsoftk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681098"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(y_train * np.log(sigsoftk)).sum() / X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 120)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 120)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.33333333, -2.26666667, -1.        , -0.13333333])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- (y_train * (1 - sigsoftk))[0,0] * X_train[:,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad for class 0: [ 0.31222222 -0.09805556  0.77111111  0.31555556]\n",
      "Grad for class 1: [-0.21611111  0.00611111 -0.30555556 -0.08527778]\n",
      "Grad for class 2: [-0.09611111  0.09194444 -0.46555556 -0.23027778]\n"
     ]
    }
   ],
   "source": [
    "for k in range(y_train.shape[0]):\n",
    "    grad = ((sigsoftk - y_train)[k,:] * X_train).sum(axis=1) / X_train.shape[1]\n",
    "    print(f\"Grad for class {k}: {grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical grad for class 0: [-2.20888863  1.73833364  1.77138887]\n",
      "Numerical grad for class 1: [ 1.10444487 -3.47666618  1.77138887]\n",
      "Numerical grad for class 2: [ 1.10444487  1.73833364 -3.54277746]\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-10\n",
    "onesvect = np.ones((1, nclasses))\n",
    "\n",
    "for k in range(y_train.shape[0]):\n",
    "    theta_plus = np.copy(theta)\n",
    "    theta_plus[:,k] = theta_plus[:,k] + epsilon\n",
    "    theta_minus = np.copy(theta)\n",
    "    theta_minus[:,k] = theta_minus[:,k] - epsilon\n",
    "\n",
    "    Svals_plus = np.exp(theta_plus.T @ X_train)\n",
    "    sigsoftk_plus = Svals_plus / (onesvect @ Svals_plus)\n",
    "\n",
    "    Svals_minus = np.exp(theta_minus.T @ X_train)\n",
    "    sigsoftk_minus = Svals_minus / (onesvect @ Svals_minus)\n",
    "    \n",
    "    cost_plus = -(y_train * np.log(sigsoftk_plus)).sum(axis=1) / X_train.shape[1]\n",
    "    cost_minus = -(y_train * np.log(sigsoftk_minus)).sum(axis=1) / X_train.shape[1]\n",
    "\n",
    "    grad = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "    print(f\"Numerical grad for class {k}: {grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0: 0.7071795173842598\n",
      "Cost at iteration 1: 0.6904500363239826\n",
      "Cost at iteration 2: 0.6752485443221061\n",
      "Cost at iteration 3: 0.6613736049416623\n",
      "Cost at iteration 4: 0.648655121082047\n",
      "Cost at iteration 5: 0.6369489451929752\n",
      "Cost at iteration 6: 0.6261327153049528\n",
      "Cost at iteration 7: 0.6161019880998508\n",
      "Cost at iteration 8: 0.6067675660031928\n",
      "Cost at iteration 9: 0.5980526807906635\n",
      "Cost at iteration 10: 0.5898914875394001\n",
      "Cost at iteration 11: 0.5822269088306579\n",
      "Cost at iteration 12: 0.5750102142254339\n",
      "Cost at iteration 13: 0.568199359748727\n",
      "Cost at iteration 14: 0.5617601546213253\n",
      "Cost at iteration 15: 0.5556655733889159\n",
      "Cost at iteration 16: 0.5499010299914993\n",
      "Cost at iteration 17: 0.5444672008947435\n",
      "Cost at iteration 18: 0.5394007277383752\n",
      "Cost at iteration 19: 0.5347874148170592\n",
      "Cost at iteration 20: 0.5308532417335939\n",
      "Cost at iteration 21: 0.5279749764032333\n",
      "Cost at iteration 22: 0.5271275381233116\n",
      "Cost at iteration 23: 0.5294553888790171\n",
      "Cost at iteration 24: 0.538564855954395\n",
      "Cost at iteration 25: 0.5548630905982823\n",
      "Cost at iteration 26: 0.5876053773727816\n",
      "Cost at iteration 27: 0.6162979526016957\n",
      "Cost at iteration 28: 0.663922387922824\n",
      "Cost at iteration 29: 0.6618045281599761\n",
      "Cost at iteration 30: 0.6960248779327346\n",
      "Cost at iteration 31: 0.6645008604694737\n",
      "Cost at iteration 32: 0.6924982712008205\n",
      "Cost at iteration 33: 0.6568137520062486\n",
      "Cost at iteration 34: 0.6843357272930279\n",
      "Cost at iteration 35: 0.6491072227155578\n",
      "Cost at iteration 36: 0.6768575444775017\n",
      "Cost at iteration 37: 0.6419454260051812\n",
      "Cost at iteration 38: 0.6698496323243606\n",
      "Cost at iteration 39: 0.6350782091466319\n",
      "Cost at iteration 40: 0.6630468584635987\n",
      "Cost at iteration 41: 0.6283986384022294\n",
      "Cost at iteration 42: 0.6563682768047895\n",
      "Cost at iteration 43: 0.6218711493875188\n",
      "Cost at iteration 44: 0.6497897334866907\n",
      "Cost at iteration 45: 0.6154778350253746\n",
      "Cost at iteration 46: 0.6432987217198487\n",
      "Cost at iteration 47: 0.6092049368377769\n",
      "Cost at iteration 48: 0.6368852576558096\n",
      "Cost at iteration 49: 0.6030404822227616\n",
      "Cost at iteration 50: 0.6305405829944185\n",
      "Cost at iteration 51: 0.5969738873575233\n",
      "Cost at iteration 52: 0.6242569838438582\n",
      "Cost at iteration 53: 0.5909957884228699\n",
      "Cost at iteration 54: 0.618027685887902\n",
      "Cost at iteration 55: 0.5850978913717758\n",
      "Cost at iteration 56: 0.6118467448684117\n",
      "Cost at iteration 57: 0.579272835535231\n",
      "Cost at iteration 58: 0.6057089444961483\n",
      "Cost at iteration 59: 0.5735140751860778\n",
      "Cost at iteration 60: 0.5996097074236157\n",
      "Cost at iteration 61: 0.5678157783924328\n",
      "Cost at iteration 62: 0.5935450191091702\n",
      "Cost at iteration 63: 0.5621727408350737\n",
      "Cost at iteration 64: 0.5875113628716037\n",
      "Cost at iteration 65: 0.5565803122134216\n",
      "Cost at iteration 66: 0.5815056643727422\n",
      "Cost at iteration 67: 0.5510343332030548\n",
      "Cost at iteration 68: 0.5755252440164785\n",
      "Cost at iteration 69: 0.5455310812848523\n",
      "Cost at iteration 70: 0.5695677760166723\n",
      "Cost at iteration 71: 0.5400672240680512\n",
      "Cost at iteration 72: 0.563631253109145\n",
      "Cost at iteration 73: 0.5346397789743775\n",
      "Cost at iteration 74: 0.5577139560637543\n",
      "Cost at iteration 75: 0.5292460783479215\n",
      "Cost at iteration 76: 0.5518144272988382\n",
      "Cost at iteration 77: 0.5238837392152906\n",
      "Cost at iteration 78: 0.5459314480192449\n",
      "Cost at iteration 79: 0.5185506370507199\n",
      "Cost at iteration 80: 0.5400640183964226\n",
      "Cost at iteration 81: 0.5132448830072708\n",
      "Cost at iteration 82: 0.534211340389012\n",
      "Cost at iteration 83: 0.5079648041628945\n",
      "Cost at iteration 84: 0.5283728028685423\n",
      "Cost at iteration 85: 0.5027089264026462\n",
      "Cost at iteration 86: 0.5225479687698781\n",
      "Cost at iteration 87: 0.4974759596187492\n",
      "Cost at iteration 88: 0.5167365640321995\n",
      "Cost at iteration 89: 0.4922647849608316\n",
      "Cost at iteration 90: 0.5109384681351875\n",
      "Cost at iteration 91: 0.48707444391144417\n",
      "Cost at iteration 92: 0.5051537060682055\n",
      "Cost at iteration 93: 0.4819041289983914\n",
      "Cost at iteration 94: 0.49938244159865364\n",
      "Cost at iteration 95: 0.4767531759867208\n",
      "Cost at iteration 96: 0.49362497173031117\n",
      "Cost at iteration 97: 0.47162105742046784\n",
      "Cost at iteration 98: 0.48788172226409965\n",
      "Cost at iteration 99: 0.4665073774081965\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "for i in range(100):\n",
    "    grads = np.zeros_like(theta)\n",
    "    for k in range(y_train.shape[0]):\n",
    "        grad = ((sigsoftk - y_train)[k,:] * X_train).sum(axis=1) / X_train.shape[1]\n",
    "        grads[:,k] = grad\n",
    "    \n",
    "    theta = theta - alpha * grads\n",
    "    Svals = np.exp(theta.T @ X_train)\n",
    "    Svalstot = onesvect @ Svals\n",
    "    sigsoftk = Svals / Svalstot\n",
    "    print(f\"Cost at iteration {i}: {-(y_train * np.log(sigsoftk)).sum() / X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
