{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character level language model - Dinosaurus land\n",
    "### Keras Implementation of the Deep-Learning Specializiation project\n",
    "\n",
    "\n",
    "Naming new dinos using RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerardoduran/anaconda/envs/deeplearning/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, SimpleRNN, Activation, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LambdaCallback\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ix(encoding):\n",
    "    \"\"\"\n",
    "    Decode an encoded dinosaur sequence presented as an\n",
    "    (n,1) numpy array\n",
    "    \"\"\"\n",
    "    string = \"\".join(ix_to_char[ix] for ix in encoding.ravel())\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"dinos.txt\", \"r\") as f:\n",
    "    dinos = f.read().lower()\n",
    "characters = sorted(list(set(dinos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at a small sample of the names in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['opisthocoelicaudia', 'skeleton', 'marshosaurus', 'tototlmimus',\n",
       "       'ozraptor', 'hylosaurus', 'elvisaurus'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(1643)\n",
    "np.random.choice(dinos.split(), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map from all characters in the training dataset to a uniquex index\n",
    "char_to_ix = {ix:char for char, ix in enumerate(characters)}\n",
    "# Reverse map of char_to_ix to retrieve the index given the character\n",
    "ix_to_char = {char:ix for char, ix in enumerate(characters,)}\n",
    "\n",
    "nchars = len(characters)\n",
    "nvocab = len(dinos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 19,903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((19903, 10, 1), (19903, 27))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the sequence to pass as training example\n",
    "seqlen = 10\n",
    "xtrain, ytrain = [], []\n",
    "for i in range(0, nvocab - seqlen):\n",
    "    xt = dinos[i: i + seqlen]\n",
    "    yt = dinos[i + seqlen]\n",
    "    xtrain.append([char_to_ix[char] for char in xt])\n",
    "    ytrain.append([char_to_ix[char] for char in yt])\n",
    "    \n",
    "# training dataset is now\n",
    "# of shape (xtrain X seqlen)\n",
    "print(f\"Number of training instances: {len(xtrain):,}\")\n",
    "\n",
    "# Reshaping into the form:\n",
    "# nfeatures X timesteps X features\n",
    "xtrain = np.reshape(xtrain, (-1, seqlen, 1))\n",
    "# Normalizing values\n",
    "#xtrain = xtrain / nvocab\n",
    "# Transorming output values to be\n",
    "# One-hot encoded\n",
    "ytrain = to_categorical(ytrain)\n",
    "xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First five instances in the training dataset: A `seqlen` number characters followed by the next character of the dinosaur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  3  8  5 14 15 19  1 21]\n",
      "'aachenosau'\n",
      "'r'\n",
      "\n",
      "[ 1  3  8  5 14 15 19  1 21 18]\n",
      "'achenosaur'\n",
      "'u'\n",
      "\n",
      "[ 3  8  5 14 15 19  1 21 18 21]\n",
      "'chenosauru'\n",
      "'s'\n",
      "\n",
      "[ 8  5 14 15 19  1 21 18 21 19]\n",
      "'henosaurus'\n",
      "'\\n'\n",
      "\n",
      "[ 5 14 15 19  1 21 18 21 19  0]\n",
      "'enosaurus\\n'\n",
      "'a'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(xtrain[i].ravel())\n",
    "    print(repr(decode_ix(xtrain[i])))\n",
    "    print(repr(ix_to_char[np.where(ytrain[i] == 1)[0][0]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19903/19903 [==============================] - 3s 164us/step - loss: 2.4775\n",
      "Epoch 2/50\n",
      "19903/19903 [==============================] - 3s 159us/step - loss: 2.3125\n",
      "Epoch 3/50\n",
      "19903/19903 [==============================] - 3s 162us/step - loss: 2.2315\n",
      "Epoch 4/50\n",
      "19903/19903 [==============================] - 3s 150us/step - loss: 2.1589\n",
      "Epoch 5/50\n",
      "19903/19903 [==============================] - 3s 149us/step - loss: 2.1094\n",
      "Epoch 6/50\n",
      "19903/19903 [==============================] - 3s 151us/step - loss: 2.0562\n",
      "Epoch 7/50\n",
      "19903/19903 [==============================] - 3s 149us/step - loss: 2.0176\n",
      "Epoch 8/50\n",
      "19903/19903 [==============================] - 3s 148us/step - loss: 1.9741\n",
      "Epoch 9/50\n",
      "19903/19903 [==============================] - 3s 148us/step - loss: 1.9428\n",
      "Epoch 10/50\n",
      "19903/19903 [==============================] - 3s 148us/step - loss: 1.9138\n",
      "Epoch 11/50\n",
      "19903/19903 [==============================] - 3s 147us/step - loss: 1.8810\n",
      "Epoch 12/50\n",
      "19903/19903 [==============================] - 3s 147us/step - loss: 1.8526\n",
      "Epoch 13/50\n",
      "19903/19903 [==============================] - 3s 148us/step - loss: 1.8220\n",
      "Epoch 14/50\n",
      "19903/19903 [==============================] - 4s 179us/step - loss: 1.8008\n",
      "Epoch 15/50\n",
      "19903/19903 [==============================] - 3s 157us/step - loss: 1.7757\n",
      "Epoch 16/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.7510\n",
      "Epoch 17/50\n",
      "19903/19903 [==============================] - 4s 177us/step - loss: 1.7274\n",
      "Epoch 18/50\n",
      "19903/19903 [==============================] - 3s 170us/step - loss: 1.7024\n",
      "Epoch 19/50\n",
      "19903/19903 [==============================] - 3s 159us/step - loss: 1.6801\n",
      "Epoch 20/50\n",
      "19903/19903 [==============================] - 3s 155us/step - loss: 1.6588\n",
      "Epoch 21/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.6373\n",
      "Epoch 22/50\n",
      "19903/19903 [==============================] - 3s 159us/step - loss: 1.6180\n",
      "Epoch 23/50\n",
      "19903/19903 [==============================] - 3s 157us/step - loss: 1.5938\n",
      "Epoch 24/50\n",
      "19903/19903 [==============================] - 3s 157us/step - loss: 1.5757\n",
      "Epoch 25/50\n",
      "19903/19903 [==============================] - 3s 156us/step - loss: 1.5558\n",
      "Epoch 26/50\n",
      "19903/19903 [==============================] - 3s 170us/step - loss: 1.5324\n",
      "Epoch 27/50\n",
      "19903/19903 [==============================] - 3s 168us/step - loss: 1.5141\n",
      "Epoch 28/50\n",
      "19903/19903 [==============================] - 4s 184us/step - loss: 1.4990\n",
      "Epoch 29/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.4854\n",
      "Epoch 30/50\n",
      "19903/19903 [==============================] - 4s 186us/step - loss: 1.4648\n",
      "Epoch 31/50\n",
      "19903/19903 [==============================] - 3s 161us/step - loss: 1.4492\n",
      "Epoch 32/50\n",
      "19903/19903 [==============================] - 3s 161us/step - loss: 1.4292\n",
      "Epoch 33/50\n",
      "19903/19903 [==============================] - 3s 162us/step - loss: 1.4111\n",
      "Epoch 34/50\n",
      "19903/19903 [==============================] - 3s 161us/step - loss: 1.3975\n",
      "Epoch 35/50\n",
      "19903/19903 [==============================] - 3s 161us/step - loss: 1.3846\n",
      "Epoch 36/50\n",
      "19903/19903 [==============================] - 3s 162us/step - loss: 1.3695\n",
      "Epoch 37/50\n",
      "19903/19903 [==============================] - 3s 162us/step - loss: 1.3510\n",
      "Epoch 38/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.3428\n",
      "Epoch 39/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.3242\n",
      "Epoch 40/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.3077\n",
      "Epoch 41/50\n",
      "19903/19903 [==============================] - 3s 163us/step - loss: 1.2977\n",
      "Epoch 42/50\n",
      "19903/19903 [==============================] - 3s 165us/step - loss: 1.2860\n",
      "Epoch 43/50\n",
      "19903/19903 [==============================] - 3s 166us/step - loss: 1.2745\n",
      "Epoch 44/50\n",
      "19903/19903 [==============================] - 4s 186us/step - loss: 1.2582\n",
      "Epoch 45/50\n",
      "19903/19903 [==============================] - 4s 180us/step - loss: 1.2455\n",
      "Epoch 46/50\n",
      "19903/19903 [==============================] - 3s 173us/step - loss: 1.2371\n",
      "Epoch 47/50\n",
      "19903/19903 [==============================] - 4s 178us/step - loss: 1.2297\n",
      "Epoch 48/50\n",
      "19903/19903 [==============================] - 3s 174us/step - loss: 1.2065\n",
      "Epoch 49/50\n",
      "19903/19903 [==============================] - 4s 190us/step - loss: 1.2077\n",
      "Epoch 50/50\n",
      "19903/19903 [==============================] - 4s 189us/step - loss: 1.1876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181b353f60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "### Constructing an RNN model with keras ###\n",
    "# Input with shape of a single training instance, we\n",
    "# do not take into account the number of training examples\n",
    "xin = Input(shape=xtrain.shape[1:])\n",
    "# A recurrent neural network cell with tanh activation function\n",
    "# and 256 units\n",
    "x = SimpleRNN(256, activation=\"tanh\")(xin)\n",
    "# The output of each training example, after feeding\n",
    "# sqlen characters is a desne \"feedforward\" neural network\n",
    "# with softax activation function\n",
    "x = Dense(ytrain.shape[1], activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=xin, outputs=x)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(xtrain, ytrain, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 1, 3, 15, 19, 1, 21, 18, 21, 19]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:'r\\nsmilodon'\n",
      "\n",
      "ciangonnsaurus\n",
      "aracamatitan\n",
      "atchaeoraptor\n",
      "archaeornithosaurus\n",
      "aracamatitan\n",
      "atchaeoraptor\n",
      "archaeornithosaurus\n",
      "aracamatitan\n",
      "atchaeoraptor\n",
      "archaeornitho\n",
      "...Done...\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(xtrain)-1)\n",
    "pattern = xtrain[start].ravel()\n",
    "print(\"Seed:\", end=\"\")\n",
    "print(repr(''.join([ix_to_char[value] for value in pattern])))\n",
    "# generate characters\n",
    "for i in range(150):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = ix_to_char[index]\n",
    "    seq_in = [ix_to_char[value] for value in pattern]\n",
    "    print(result, end=\"\")\n",
    "    pattern = np.append(pattern, index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\n...Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset: Outputs\n",
    "dinos_list = [[char_to_ix[c] for c in d + \"\\n\"] for d in dinos.split()]\n",
    "maxlen =  len(max(dinos_list, key=len))\n",
    "ndinos = len(dinos_list)\n",
    "nchars = len(characters)\n",
    "xtrain = np.zeros((ndinos, maxlen, nchars))\n",
    "ytrain = np.zeros((ndinos, maxlen, nchars))\n",
    "\n",
    "xtrain = np.zeros((ndinos, maxlen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xin = Input(shape=(maxlen,))\n",
    "x = SimpleRNN(10, activation=\"tanh\")(xin)\n",
    "x = Dense()\n",
    "x = Activation(\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=xin, outputs=x)\n",
    "model.compile(\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704, 0.03703704, 0.03703704, 0.03703704,\n",
       "       0.03703704, 0.03703704], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.zeros((1, maxlen, nchars)))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
