{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "The figure below shows a Recurrent Neural Network (RNN) with one input unit x, one logistic hidden unit h, and one linear output unit $y$\n",
    "\n",
    "The RNN is unrolled in time for T=0,1, and 2.\n",
    "\n",
    "![RNN1](misc/rnn1.png)\n",
    "\n",
    "The network parameters are: $W_{xh} = 0.5, W_{hh} = -1.0, W_{hy} = -0.7$, $h_{bias}=-0.1$ and $y_{bias}=0.0$. Remember, $\\sigma(k) = \\frac{1}{1 + e^{-k}}$.\n",
    "\n",
    "The inputs at various time steps are the following:\n",
    "\n",
    "$T$ | $x$ (input)\n",
    "--- | ---\n",
    "0 | 9\n",
    "1 | 4\n",
    "2 | -2\n",
    "\n",
    "\n",
    "What is the value of the output y at $T=1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to forward propagate in a recurrent neural network?**\n",
    "\n",
    "We can think of the given neural net as a growing rnn where, after each time-step, an input is produced, the output of the net at time $t$ does not affect the hidden units in the forward progation. It then follows that in order to find the output at time 2 of this RNN, we only forward propagate twice with the same hidden units (using the logistic function), and compute the output with the linear activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6008075567320005\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "sigma = lambda k: 1 / (1 + exp(-k))\n",
    "X = [9, 4]\n",
    "Wxh, Whh, Why = 0.5, -0.1, -0.7\n",
    "hbias = -0.1\n",
    "\n",
    "# hidden from time 0:\n",
    "#    Input to hidden state\n",
    "o1 = sigma(X[0] * Wxh + hbias)\n",
    "# hidden from time 1:\n",
    "#    output from time 0 and input from time 1\n",
    "o2 = sigma((o1 * Whh) + (X[1] * Wxh) + hbias)\n",
    "# output from time 1\n",
    "output = o2 * Why\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Consider the RNN architecture above.\n",
    "\n",
    "The network parameters are:\n",
    "\n",
    "Params | Values\n",
    "--- | ---\n",
    "$W_{xh}$ | -0.1\n",
    "$W_{hh}$ | 0.5\n",
    "$W_{hy}$ | 0.25\n",
    "$h_{bias}$ | 0.4\n",
    "$y_{bias}$ | 0.0\n",
    "\n",
    "And the inputs are\n",
    "\n",
    "$T$ | $x$ (input)\n",
    "--- | ---\n",
    "0 | 18\n",
    "1 | 9\n",
    "2 | -8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19781611144141825"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [18, 9, -8]\n",
    "Wxh, Whh, Why = -0.1, 0.5, 0.25\n",
    "hbias = 0.4\n",
    "\n",
    "sigma(X[0] * Wxh + hbias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
