{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will design a neural net language model. The model will learn to predict the next word given the previous three words. The network looks like this:\n",
    "\n",
    "![Network](misc/proga2.png)\n",
    "\n",
    "The starter code implements a basic framework for training neural nets with mini-batch gradient descent. Your job is to **write code to complete the implementation of forward and back propagation**. See the README file for a description of the dataset, starter code and how to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = testData\n",
      "  [2,1] = trainData\n",
      "  [3,1] = validData\n",
      "  [4,1] = vocab\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "load programming_assignment_2/data.mat\n",
    "fieldnames(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data.vocab` contains the vocabulary of 250 words. Training, validation and\n",
    "test sets are in `data.trainData`, `data.validData` and `data.testData`  respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = all\n",
      "  [1,2] = set\n",
      "  [1,3] = just\n",
      "  [1,4] = show\n",
      "  [1,5] = being\n",
      "  [1,6] = money\n",
      "  [1,7] = over\n",
      "  [1,8] = both\n",
      "  [1,9] = years\n",
      "  [1,10] = four\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data.vocab(1:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   372550        4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.testData = data.testData';\n",
    "data.validData = data.validData';\n",
    "data.trainData = data.trainData';\n",
    "size(data.trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   28   26   90  144\n",
      "  184   44  249  117\n",
      "  183   32   76  122\n",
      "  117  247  201  186\n",
      "  223  190  249    6\n",
      "   42   74   26   32\n",
      "  242   32  223   32\n",
      "  223   32  158  144\n",
      "   74   32  221   32\n",
      "   42  192   91   68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.trainData(1:10, 1:4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = were\n",
      "  [1,2] = not\n",
      "  [1,3] = the\n",
      "  [1,4] = first\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "% --2 column, all rows--\n",
    "data.vocab([184, 44, 249, 117])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'data.trainData' is a matrix of 372550 X 4. This means there are 372550\n",
    "training cases and 4 words per training case. Each entry is an integer that is\n",
    "the index of a word in the vocabulary. So each row represents a sequence of 4\n",
    "words. 'data.validData' and 'data.testData' are also similar. They contain\n",
    "46,568 4-grams each. **All three need to be separated into inputs and targets\n",
    "and the training set needs to be split into mini-batches**. The file load_data.m provides code for doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addpath(\"programming_assignment_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: load: '/Users/gerardoduran/Documents/github/machine_learning/nnets_coursera/notebooks/programming_assignment_2/data.mat' found by searching load path\n",
      "warning: called from\n",
      "    load_data at line 16 column 1\n"
     ]
    }
   ],
   "source": [
    "[train_x, train_t, valid_x, valid_t, test_x, test_t, vocab] = load_data(1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
