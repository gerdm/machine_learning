{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will design a neural net language model. The model will learn to predict the next word given the previous three words. The network looks like this:\n",
    "\n",
    "![Network](misc/proga2.png)\n",
    "\n",
    "The starter code implements a basic framework for training neural nets with mini-batch gradient descent. Your job is to **write code to complete the implementation of forward and back propagation**. See the README file for a description of the dataset, starter code and how to run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax output\n",
    "$$\n",
    "    y_i = \\frac{e^{z_i}}{\\sum_{j}e^{z_j}}\n",
    "$$\n",
    "\n",
    "Implies,\n",
    "$$\n",
    "    \\frac{\\partial y_i}{\\partial z_i} = y_i (1 - y_i)\n",
    "$$\n",
    "\n",
    "We denote the **cross-entropy** cost function $C$ as:\n",
    "$$\n",
    "    C = -\\sum_j t_j \\log y_j\n",
    "$$\n",
    "With partial w.r.t. output $i$ ($z_i$) as\n",
    "$$\n",
    "    \\frac{\\partial C}{\\partial z_i} = \\frac{\\partial C}{\\partial y_i} \\frac{\\partial y_i}{\\partial z_i} = y_i - t_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = testData\n",
      "  [2,1] = trainData\n",
      "  [3,1] = validData\n",
      "  [4,1] = vocab\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "load programming_assignment_2/data.mat\n",
    "fieldnames(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data.vocab` contains the vocabulary of 250 words. Training, validation and\n",
    "test sets are in `data.trainData`, `data.validData` and `data.testData`  respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = all\n",
      "  [1,2] = set\n",
      "  [1,3] = just\n",
      "  [1,4] = show\n",
      "  [1,5] = being\n",
      "  [1,6] = money\n",
      "  [1,7] = over\n",
      "  [1,8] = both\n",
      "  [1,9] = years\n",
      "  [1,10] = four\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data.vocab(1:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   372550        4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.testData = data.testData';\n",
    "data.validData = data.validData';\n",
    "data.trainData = data.trainData';\n",
    "size(data.trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "   28   26   90  144\n",
      "  184   44  249  117\n",
      "  183   32   76  122\n",
      "  117  247  201  186\n",
      "  223  190  249    6\n",
      "   42   74   26   32\n",
      "  242   32  223   32\n",
      "  223   32  158  144\n",
      "   74   32  221   32\n",
      "   42  192   91   68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.trainData(1:10, 1:4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans = \n",
      "{\n",
      "  [1,1] = were\n",
      "  [1,2] = not\n",
      "  [1,3] = the\n",
      "  [1,4] = first\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "% --2 column, all rows--\n",
    "data.vocab([184, 44, 249, 117])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'data.trainData' is a matrix of 372550 X 4. This means there are 372550\n",
    "training cases and 4 words per training case. Each entry is an integer that is\n",
    "the index of a word in the vocabulary. So each row represents a sequence of 4\n",
    "words. 'data.validData' and 'data.testData' are also similar. They contain\n",
    "46,568 4-grams each. **All three need to be separated into inputs and targets\n",
    "and the training set needs to be split into mini-batches**. The file load_data.m provides code for doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addpath(\"programming_assignment_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: load: '/Users/gerardoduran/Documents/github/machine_learning/nnets_coursera/notebooks/programming_assignment_2/data.mat' found by searching load path\n",
      "warning: called from\n",
      "    load_data at line 16 column 1\n"
     ]
    }
   ],
   "source": [
    "[train_x, train_t, valid_x, valid_t, test_x, test_t, vocab] = load_data(100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: load: '/Users/gerardoduran/Documents/github/machine_learning/nnets_coursera/notebooks/programming_assignment_2/data.mat' found by searching load path\n",
      "warning: called from\n",
      "    load_data at line 16 column 1\n",
      "    train at line 32 column 30\n",
      "Epoch 1\n",
      "Batch 100 Train CE 5.521\n",
      "Batch 200 Train CE 5.521\n",
      "Batch 300 Train CE 5.521\n",
      "Batch 400 Train CE 5.521\n",
      "Batch 500 Train CE 5.521\n",
      "Batch 600 Train CE 5.521\n",
      "Batch 700 Train CE 5.521\n",
      "Batch 800 Train CE 5.521\n",
      "Batch 900 Train CE 5.521\n",
      "Batch 1000 Train CE 5.521\n",
      "Running validation ... Validation CE 5.521\n",
      "Batch 1100 Train CE 5.521\n",
      "Batch 1200 Train CE 5.521\n",
      "Batch 1300 Train CE 5.521\n",
      "Batch 1400 Train CE 5.521\n",
      "Batch 1500 Train CE 5.521\n",
      "Batch 1600 Train CE 5.521\n",
      "Batch 1700 Train CE 5.521\n",
      "Batch 1800 Train CE 5.521\n",
      "Batch 1900 Train CE 5.521\n",
      "Batch 2000 Train CE 5.521\n",
      "Running validation ... Validation CE 5.521\n",
      "Batch 2100 Train CE 5.521\n",
      "Batch 2200 Train CE 5.521\n",
      "Batch 2300 Train CE 5.521\n",
      "Batch 2400 Train CE 5.521\n",
      "Batch 2500 Train CE 5.521\n",
      "Batch 2600 Train CE 5.521\n",
      "Batch 2700 Train CE 5.521\n",
      "Batch 2800 Train CE 5.521\n",
      "Batch 2900 Train CE 5.521\n",
      "Batch 3000 Train CE 5.521\n",
      "Running validation ... Validation CE 5.521\n",
      "Batch 3100 Train CE 5.521\n",
      "Batch 3200 Train CE 5.521\n",
      "Batch 3300 Train CE 5.521\n",
      "Batch 3400 Train CE 5.521\n",
      "Batch 3500 Train CE 5.521\n",
      "Batch 3600 Train CE 5.521\n",
      "Batch 3700 Train CE 5.521\n",
      "Average Training CE 5.521\n",
      "Finished Training.\n",
      "Final Training CE 5.521\n",
      "Final Validation CE 5.521\n",
      "Final Test CE 5.521\n",
      "Training took 19.49 seconds\n"
     ]
    }
   ],
   "source": [
    "%Output with the initial code\n",
    "model = train(1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
